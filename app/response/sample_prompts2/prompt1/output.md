了解しました。第1章〜第3章の内容について、情報系の大学院1年生レベルの読者を想定し、専門的な内容を省略せず、図や数式を交えて丁寧に解説する日本語のマークダウン形式の資料を作成します。

画像は信頼性の高い資料から引用し、説明は英語・中国語圏の文献も活用して統合的かつ分かりやすく仕上げます。

準備が整い次第、お知らせいたします。

## 第1章：コンピュータサイエンスの第一歩

コンピュータサイエンスとは、コンピュータを使っていかに問題を解決するかを探求する学問です。コンピュータは基本的に**入力**されたデータに対して**プログラム**（アルゴリズム）の指示通りに処理を行い、その結果を**出力**する機械です ([〖机器学习〗一些基本概念及符号系统 - 昕-2008 - 博客园](https://www.cnblogs.com/Belter/p/6323390.html#:~:text=%E5%A6%82%E6%9E%9C%E5%B0%86%E4%B8%80%E4%B8%AA%E7%A8%8B%E5%BA%8F%E5%A4%A7%E8%87%B4%E5%88%86%E4%B8%BA%E4%B8%89%E4%B8%AA%E9%83%A8%E5%88%86%EF%BC%9A%E8%BE%93%E5%85%A5%E3%80%81%E8%BE%93%E5%87%BA%E5%92%8C%E7%AE%97%E6%B3%95%EF%BC%8C%E9%82%A3%E4%B9%88%E4%BC%A0%E7%BB%9F%E7%BC%96%E7%A8%8B%E4%B8%AD%E5%B7%B2%E7%9F%A5%E7%9A%84%E6%98%AF%E8%BE%93%E5%85%A5%E5%92%8C%E7%AE%97%E6%B3%95%EF%BC%8C%E9%9C%80%E8%A6%81%E6%B1%82%E8%BE%93%E5%87%BA%EF%BC%9B%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%88%99%E6%98%AF%E5%B7%B2%E7%9F%A5%E8%BE%93%E5%85%A5%E5%92%8C%E8%BE%93%E5%87%BA%EF%BC%8C%E9%9C%80%E8%A6%81%E9%80%9A%E8%BF%87%E8%AE%AD%E7%BB%83%EF%BC%88%E5%AD%A6%E4%B9%A0%EF%BC%89%E6%9D%A5%E5%BE%97%E5%88%B0%E6%9C%89%E6%B3%9B%E5%8C%96%E8%83%BD%20%E5%8A%9B%E7%9A%84%E7%AE%97%E6%B3%95%E3%80%82))。つまり、人間があらかじめ決めた手順（プログラム）に従って動作し、自動で計算や判断を高速に行います。まずは、コンピュータが情報を扱う仕組みやプログラムの基礎について見ていきましょう。

### 情報の表現と2進法

コンピュータは内部で**2進数（バイナリ）**を使って情報を表現しています。私たちが日常で使う10進数（0～9の数字）では桁が繰り上がって数を表現しますが、2進数では利用できる数字が0と1の2種類だけなので、数が大きくなると桁数が増えていきます ([コンピュータが２進数を使うのはなぜ？ | なぜ？を科学する | アマノ科学教室](https://zai-amano.jp/why/binary/#:~:text=%E7%A7%81%E3%81%9F%E3%81%A1%E3%81%8C%E6%99%AE%E6%AE%B5%E4%BD%BF%E3%81%A3%E3%81%A6%E3%81%84%E3%82%8B%E6%95%B0%E5%AD%97%E3%81%AF10%E9%80%B2%E6%95%B0%E3%81%A7%E3%81%99%E3%80%8210%E9%80%B2%E6%95%B0%E3%81%A8%E3%81%84%E3%81%86%E3%81%AE%E3%81%AF%EF%BC%91%E6%A1%81%E3%81%A710%E7%A8%AE%E9%A1%9E%E3%81%AE%E6%95%B0%E5%AD%97%E3%80%81%E3%81%A4%E3%81%BE%E3%82%8A%EF%BC%90%EF%BD%9E%EF%BC%99%E3%81%BE%E3%81%A7%E3%81%AE%E6%95%B0%E5%AD%97%E3%81%A7%E8%A1%A8%E3%81%97%E3%81%BE%E3%81%99%E3%80%82%E3%81%A0%E3%81%8B%E3%82%89%EF%BC%90%E3%81%8B%E3%82%89%EF%BC%99%E3%81%BE%E3%81%A7%E6%95%B0%E3%81%88%E3%81%9F%E3%82%89%E3%80%81%E3%81%9D%E3%81%AE%E6%AC%A1%E3%81%AF%E6%A1%81%E3%81%8C%E5%A2%97%E3%81%88%20%E3%81%A610%EF%BD%A411%EF%BD%A412%EF%BD%A4%EF%BD%A5%EF%BD%A5%EF%BD%A519%EF%BD%A420%EF%BD%A421%EF%BD%A4%E3%81%A8%E9%80%B2%E3%81%BF%E3%80%8199%E3%81%BE%E3%81%A7%E3%81%8F%E3%82%8B%E3%81%A8%E3%80%81%E3%81%BE%E3%81%9F%E6%A1%81%E3%81%8C%E5%A2%97%E3%81%88%E3%81%A6100%EF%BD%A4101%EF%BD%A4102%EF%BD%A5%EF%BD%A5%EF%BD%A5%E3%81%A8%E3%81%AA%E3%81%A3%E3%81%A6%E3%81%84%E3%81%8D%E3%81%BE%E3%81%99%E3%80%82%202%E9%80%B2%E6%95%B0%E3%82%82%E5%90%8C%E3%81%98%E8%80%83%E3%81%88%E6%96%B9%E3%81%A7%E3%80%81%E4%BD%BF%E3%81%88%E3%82%8B%E6%95%B0%E5%AD%97%E3%81%AF0%E3%81%A81%E3%81%AE2%E7%A8%AE%E9%A1%9E%E3%81%A0%E3%81%91%E3%81%A7%E3%80%81%E6%95%B0%E3%81%8C%E5%A4%A7%E3%81%8D%E3%81%8F%E3%81%AA%E3%82%8B%E3%81%AB%E3%81%A4%E3%82%8C%E6%A1%81%E3%81%8C%E5%A2%97%E3%81%88%E3%81%A6%E3%81%84%E3%81%8D%E3%81%BE%E3%81%99%E3%80%82))。例えば**10進数の11**は、2進数では**`1011`**と表せます ([コンピュータが２進数を使うのはなぜ？ | なぜ？を科学する | アマノ科学教室](https://zai-amano.jp/why/binary/#:~:text=%E3%81%A4%E3%81%BE%E3%82%8A10%E9%80%B2%E6%95%B0%E3%81%AE11%E3%82%922%E9%80%B2%E6%95%B0%E3%81%A7%E8%A1%A8%E3%81%99%E3%81%A81011%E3%81%A8%E3%81%AA%E3%82%8A%E3%81%BE%E3%81%99%E3%80%82))。このように0と1の並びで数値を表現するのが2進数です。

では、なぜコンピュータは0と1しか使わない2進数で情報を扱うのでしょうか？ それは、コンピュータ内部では電気信号の**ON/OFF（高電圧/低電圧）**によって情報を表現しているからです ([コンピュータが２進数を使うのはなぜ？ | なぜ？を科学する | アマノ科学教室](https://zai-amano.jp/why/binary/#:~:text=%E3%82%B3%E3%83%B3%E3%83%94%E3%83%A5%E3%83%BC%E3%82%BF%E3%81%AF%E3%82%AD%E3%83%BC%E3%83%9C%E3%83%BC%E3%83%89%E3%81%8B%E3%82%89%E5%85%A5%E5%8A%9B%E3%81%95%E3%82%8C%E3%82%8B0%EF%BD%9E9%E3%81%BE%E3%81%A7%E3%81%AE%E6%95%B0%E5%AD%97%E3%80%81A%EF%BD%9EZ%E3%81%BE%E3%81%A7%E3%81%AE%E3%82%A2%E3%83%AB%E3%83%95%E3%82%A1%E3%83%99%E3%83%83%E3%83%88%E3%80%81%E3%81%82%EF%BD%9E%E3%82%93%E3%81%BE%E3%81%A7%E3%81%AE%E3%81%B2%E3%82%89%E3%81%8C%E3%81%AA%E3%80%81%EF%BC%8B%EF%BC%8D%E3%81%AA%E3%81%A9%E3%81%AE%E7%89%B9%E6%AE%8A%E6%96%87%E5%AD%97%E3%81%AA%E3%81%A9%E5%85%A8%E9%83%A8%E3%81%A7%EF%BC%92%EF%BC%90%EF%BC%90%E7%A8%AE%E9%A1%9E%E4%BB%A5%E4%B8%8A%E3%81%AE%E6%96%87%E5%AD%97%E3%82%84%E6%95%B0%E5%AD%97%20%E3%82%92%E5%88%A4%E6%96%AD%E3%81%97%E3%81%AA%E3%81%8F%E3%81%A6%E3%81%AF%E3%81%AA%E3%82%8A%E3%81%BE%E3%81%9B%E3%82%93%E3%80%82%E3%81%97%E3%81%8B%E3%81%97%E3%80%81%E3%82%B3%E3%83%B3%E3%83%94%E3%83%A5%E3%83%BC%E3%82%BF%E3%81%8C%E3%82%8F%E3%81%8B%E3%82%8B%E3%81%93%E3%81%A8%E3%81%AF%E9%9B%BB%E6%B5%81%E3%82%84%E9%9B%BB%E5%9C%A7%E3%81%AA%E3%81%A9%E3%81%AE%E9%9B%BB%E6%B0%97%E7%9A%84%E3%81%AA%E4%BF%A1%E5%8F%B7%E3%81%A7%E3%81%97%E3%81%8B%E3%82%8F%E3%81%8B%E3%82%8A%E3%81%BE%E3%81%9B%E3%82%93%E3%80%82%E3%81%BE%E3%81%9F%E3%80%81%E5%87%A6%E7%90%86%E9%80%9F%E5%BA%A6%E3%82%84%E5%B0%8F%E5%9E%8B%E5%8C%96%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AB%E3%81%AF%E9%9B%BB%E5%9C%A7%E3%81%AF%E6%A5%B5%E5%8A%9B%E4%BD%8E%E3%81%84%E5%80%A4%EF%BC%88%20%EF%BC%95V)) ([コンピュータが２進数を使うのはなぜ？ | なぜ？を科学する | アマノ科学教室](https://zai-amano.jp/why/binary/#:~:text=%E3%81%9D%E3%81%93%E3%81%A7%E3%80%81%EF%BC%92%E9%80%B2%E6%95%B0%E3%81%AE%E5%87%BA%E7%95%AA%E3%81%A7%E3%81%99%E3%80%82%EF%BC%91%E3%82%92%E9%9B%BB%E6%B5%81%E3%81%8C%E6%B5%81%E3%82%8C%E3%81%A6%E3%81%84%E3%82%8B%EF%BC%88%E9%9B%BB%E5%9C%A7%E3%81%8C%E9%AB%98%E3%81%84%EF%BC%89%E3%80%81%EF%BC%90%E3%82%92%E9%9B%BB%E6%B5%81%E3%81%8C%E6%B5%81%E3%82%8C%E3%81%A6%E3%81%84%E3%81%AA%E3%81%84%EF%BC%88%E9%9B%BB%E5%9C%A7%E3%81%8C%E4%BD%8E%E3%81%84%EF%BC%89%E3%81%A8%E3%81%99%E3%82%8B%E3%81%93%E3%81%A8%E3%81%A7%E3%80%81%EF%BC%91%E6%9C%AC%E3%81%AE%E7%B7%9A%E3%81%A7%E3%81%AF0%E3%81%A81%E3%81%AE%EF%BC%92%E7%A8%AE%E9%A1%9E%E3%81%AE%E8%A8%98%E5%8F%B7%E3%81%8C%E5%88%A4%E6%96%AD%E3%81%A7%E3%81%8D%E3%81%BE%E3%81%99%E3%80%82%20%EF%BC%92%E6%9C%AC%E3%81%82%E3%82%8B%E3%81%A8%EF%BC%8800%E3%80%8101%E3%80%8110%E3%80%8111%EF%BC%89%E3%81%A7%E7%B5%84%E3%81%BF%E5%90%88%E3%82%8F%E3%81%9B%E3%81%8C%EF%BC%94%E3%81%A4%E3%81%A7%E3%81%8D%E3%81%BE%E3%81%99%E3%81%8B%E3%82%89%EF%BC%94%E7%A8%AE%E9%A1%9E%E3%81%AE%E8%A8%98%E5%8F%B7%E3%81%8C%E5%88%A4%E6%96%AD%E3%81%A7%E3%81%8D%E3%81%BE%E3%81%99%E3%80%82))。0と1の二値であれば、電圧が多少ノイズで乱れても**高いか低いか**の判定は容易で誤りにくく、安定して情報を伝達できます ([コンピュータが２進数を使うのはなぜ？ | なぜ？を科学する | アマノ科学教室](https://zai-amano.jp/why/binary/#:~:text=%E3%81%BE%E3%81%9F%E3%80%81%E2%91%A1%E3%81%AE%E5%A0%B4%E5%90%88%E3%81%AF%E3%81%A1%E3%82%87%E3%81%A3%E3%81%A8%E3%81%97%E3%81%9F%E3%83%8E%E3%82%A4%E3%82%BA%EF%BC%88%E9%9B%91%E9%9F%B3%E3%80%81%E9%9B%BB%E6%B3%A2%E9%9A%9C%E5%AE%B3%EF%BC%89%E3%81%A7%E6%AD%A3%E7%A2%BA%E3%81%AA%E5%88%A4%E6%96%AD%E3%81%8C%E3%81%A7%E3%81%8D%E3%81%BE%E3%81%9B%E3%82%93%E3%80%82%20%E3%81%A0%E3%81%8B%E3%82%89%E3%80%81%E3%81%93%E3%82%8C%E3%82%89%E3%81%AF%E7%8F%BE%E5%AE%9F%E7%9A%84%E3%81%AB%E3%81%AF%E7%84%A1%E7%90%86%E3%81%AA%E6%96%B9%E6%B3%95%E3%81%A8%E3%81%AA%E3%81%A3%E3%81%A6%E3%81%97%E3%81%BE%E3%81%84%E3%81%BE%E3%81%99%E3%80%82)) ([コンピュータが２進数を使うのはなぜ？ | なぜ？を科学する | アマノ科学教室](https://zai-amano.jp/why/binary/#:~:text=%E3%81%A4%E3%81%BE%E3%82%8A%E8%A1%A8%E3%81%AE%E3%82%88%E3%81%86%E3%81%AB%EF%BC%98%E6%9C%AC%E3%81%AE%E7%B7%9A%E3%81%8C%E3%81%82%E3%82%8C%E3%81%B0256%E3%81%AE%E7%B5%84%E3%81%BF%E5%90%88%E3%82%8F%E3%81%9B%E3%81%8C%E3%81%A7%E3%81%8D%E3%82%8B%E3%81%AE%E3%81%A7%E3%80%81%E3%82%AD%E3%83%BC%E3%83%9C%E3%83%BC%E3%83%89%E3%81%AE%E6%96%87%E5%AD%97%E3%82%92%E5%85%A8%E3%81%A6%E9%9B%BB%E6%B0%97%E4%BF%A1%E5%8F%B7%E3%81%A7%E8%A1%A8%E3%81%99%E3%81%93%E3%81%A8%E3%81%8C%E3%81%A7%E3%81%8D%E3%81%BE%E3%81%99%E3%80%82%E3%81%A0%E3%81%8B%E3%82%89%E3%80%81%E3%82%B3%E3%83%B3%E3%83%94%E3%83%A5%E3%83%BC%E3%82%BF%E3%81%AF0%E3%81%A81%E3%81%AE%E6%95%B0%E5%AD%97%E3%81%A7%E5%8A%B9%E7%8E%87%E3%82%88%E3%81%8F%20%E6%AD%A3%E7%A2%BA%E3%81%AB%E5%88%A4%E6%96%AD%E3%81%A7%E3%81%8D%E3%82%8B%E3%81%AE%E3%81%A7%E3%81%99%E3%80%82%20%E3%81%93%E3%81%AE0%E3%81%A81%E3%82%92%E3%83%93%E3%83%83%E3%83%88%EF%BC%88bit%EF%BC%89%E3%81%A8%E8%A8%80%E3%81%A3%E3%81%A6%E3%80%81%E3%82%B3%E3%83%B3%E3%83%94%E3%83%A5%E3%83%BC%E3%82%BF%E3%81%8C%E6%89%B1%E3%81%86%E6%9C%80%E5%B0%8F%E5%8D%98%E4%BD%8D%E3%81%A8%E3%81%AA%E3%82%8A%E3%81%BE%E3%81%99%E3%80%82%E3%81%BE%E3%81%9F%E3%80%810%E3%81%A81%E3%81%A7%E8%A1%A8%E3%81%95%E3%82%8C%E3%81%9F%E6%96%87%E5%AD%97%E3%82%84%E8%A8%98%E5%8F%B7%E3%82%92%E3%83%90%E3%82%A4%E3%83%8A%E3%83%AA%E3%83%BC%E3%83%87%E3%83%BC%E3%82%BF%EF%BC%88%EF%BC%92%E9%80%B2%E6%95%B0%E3%81%AE%E9%9B%86%E3%81%BE%E3%82%8A%EF%BC%89%E3%81%A8%E8%A8%80%E3%81%84%E3%81%BE%E3%81%99%E3%80%82%20%E3%81%93%E3%81%AE%EF%BC%92%E5%80%A4%E3%81%AE%E4%BF%A1%E5%8F%B7%E3%81%AB%E3%82%88%E3%81%A3%E3%81%A6%E5%87%A6%E7%90%86%E3%81%95%E3%82%8C%E3%81%A6%E3%81%84%E3%82%8B%E3%83%87%E3%82%B8%E3%82%BF%E3%83%AB%E4%BF%A1%E5%8F%B7%E3%81%AF%E3%80%810%E3%81%A81%E3%81%AE%EF%BC%92%E5%80%A4%E3%81%97%E3%81%8B%E3%81%AA%E3%81%84%E3%81%AE%E3%81%A7%E3%80%81%E3%83%8E%E3%82%A4%E3%82%BA%E7%AD%89%E3%81%A7%E5%A4%89%E5%BD%A2%E3%81%97%E3%81%9F%E3%82%82%E3%81%AE%E3%82%92%E5%85%83%E3%81%AE%E3%81%8D%E3%82%8C%E3%81%84%E3%81%AA%EF%BC%92%E5%80%A4%E3%81%AE%E4%BF%A1%E5%8F%B7%E3%81%AB%E6%88%BB%E3%81%99%E3%81%93%E3%81%A8%E3%82%82%E5%8F%AF%E8%83%BD%E3%81%A8%E3%81%AA%E3%82%8A%E3%81%BE%E3%81%99%E3%80%82%20%E4%BE%8B%E3%81%88%E3%81%B0%E3%80%81%E5%AE%87%E5%AE%99%E3%81%8B%E3%82%89%E7%99%BA%E4%BF%A1%E3%81%97%E3%81%9F%E4%BF%A1%E5%8F%B7%E3%82%92%E5%9C%B0%E7%90%83%E4%B8%8A%E3%81%A7%E3%81%A8%E3%82%89%E3%81%88%E3%81%A6%E3%82%82%E3%82%B0%E3%83%8B%E3%83%A3%E3%82%B0%E3%83%8B%E3%83%A3%E3%81%AB%E3%81%AA%E3%81%A3%E3%81%A6%E3%81%97%E3%81%BE%E3%81%84%E3%81%BE%E3%81%99%E3%81%8C%E3%80%81%E3%81%93%E3%82%8C%E3%82%92%E5%85%83%E3%81%AE%EF%BC%92%E5%80%A4%E4%BF%A1%E5%8F%B7%E3%81%AB%E5%A4%89%E3%81%88%E3%82%8B%E3%81%8B%E3%82%89%E3%80%81%E7%A7%81%E3%81%9F%E3%81%A1%E3%81%AF%E3%80%81%E3%81%82%E3%81%9F%E3%81%8B%E3%82%82%E3%81%9D%E3%81%93%E3%81%AB%E3%81%84%E3%82%8B%E3%82%88%E3%81%86%E3%81%AB%E3%81%8D%E3%82%8C%E3%81%84%E3%81%AA%E7%94%BB%E5%83%8F,%E3%81%A7%E8%A6%8B%E3%82%8B%E3%81%93%E3%81%A8%E3%81%8C%E3%81%A7%E3%81%8D%E3%81%BE%E3%81%99%E3%80%82%E3%82%A2%E3%83%9D%E3%83%AD%EF%BC%91%EF%BC%91%E5%8F%B7%E3%81%8C%E6%9C%88%E3%81%AB%E7%9D%80%E9%99%B8%E3%81%97%E3%81%9F%E3%81%A8%E3%81%8D%E3%81%AF%E6%84%9F%E6%BF%80%E3%81%97%E3%81%BE%E3%81%97%E3%81%9F%E3%81%AD%E3%80%82))。例えば8本の電気信号線があれば2^8=256通りの組み合わせが表現でき、キーボードのあらゆる文字を0と1の組み合わせ（8ビット=1バイト）で符号化できます ([コンピュータが２進数を使うのはなぜ？ | なぜ？を科学する | アマノ科学教室](https://zai-amano.jp/why/binary/#:~:text=ImageImage))。この最小単位の0/1の情報を**ビット(bit)**と呼び、8ビットの集まりを**バイト(byte)**と呼びます ([コンピュータが２進数を使うのはなぜ？ | なぜ？を科学する | アマノ科学教室](https://zai-amano.jp/why/binary/#:~:text=%E3%81%A4%E3%81%BE%E3%82%8A%E8%A1%A8%E3%81%AE%E3%82%88%E3%81%86%E3%81%AB%EF%BC%98%E6%9C%AC%E3%81%AE%E7%B7%9A%E3%81%8C%E3%81%82%E3%82%8C%E3%81%B0256%E3%81%AE%E7%B5%84%E3%81%BF%E5%90%88%E3%82%8F%E3%81%9B%E3%81%8C%E3%81%A7%E3%81%8D%E3%82%8B%E3%81%AE%E3%81%A7%E3%80%81%E3%82%AD%E3%83%BC%E3%83%9C%E3%83%BC%E3%83%89%E3%81%AE%E6%96%87%E5%AD%97%E3%82%92%E5%85%A8%E3%81%A6%E9%9B%BB%E6%B0%97%E4%BF%A1%E5%8F%B7%E3%81%A7%E8%A1%A8%E3%81%99%E3%81%93%E3%81%A8%E3%81%8C%E3%81%A7%E3%81%8D%E3%81%BE%E3%81%99%E3%80%82%E3%81%A0%E3%81%8B%E3%82%89%E3%80%81%E3%82%B3%E3%83%B3%E3%83%94%E3%83%A5%E3%83%BC%E3%82%BF%E3%81%AF0%E3%81%A81%E3%81%AE%E6%95%B0%E5%AD%97%E3%81%A7%E5%8A%B9%E7%8E%87%E3%82%88%E3%81%8F%20%E6%AD%A3%E7%A2%BA%E3%81%AB%E5%88%A4%E6%96%AD%E3%81%A7%E3%81%8D%E3%82%8B%E3%81%AE%E3%81%A7%E3%81%99%E3%80%82%20%E3%81%93%E3%81%AE0%E3%81%A81%E3%82%92%E3%83%93%E3%83%83%E3%83%88%EF%BC%88bit%EF%BC%89%E3%81%A8%E8%A8%80%E3%81%A3%E3%81%A6%E3%80%81%E3%82%B3%E3%83%B3%E3%83%94%E3%83%A5%E3%83%BC%E3%82%BF%E3%81%8C%E6%89%B1%E3%81%86%E6%9C%80%E5%B0%8F%E5%8D%98%E4%BD%8D%E3%81%A8%E3%81%AA%E3%82%8A%E3%81%BE%E3%81%99%E3%80%82%E3%81%BE%E3%81%9F%E3%80%810%E3%81%A81%E3%81%A7%E8%A1%A8%E3%81%95%E3%82%8C%E3%81%9F%E6%96%87%E5%AD%97%E3%82%84%E8%A8%98%E5%8F%B7%E3%82%92%E3%83%90%E3%82%A4%E3%83%8A%E3%83%AA%E3%83%BC%E3%83%87%E3%83%BC%E3%82%BF%EF%BC%88%EF%BC%92%E9%80%B2%E6%95%B0%E3%81%AE%E9%9B%86%E3%81%BE%E3%82%8A%EF%BC%89%E3%81%A8%E8%A8%80%E3%81%84%E3%81%BE%E3%81%99%E3%80%82%20%E3%81%93%E3%81%AE%EF%BC%92%E5%80%A4%E3%81%AE%E4%BF%A1%E5%8F%B7%E3%81%AB%E3%82%88%E3%81%A3%E3%81%A6%E5%87%A6%E7%90%86%E3%81%95%E3%82%8C%E3%81%A6%E3%81%84%E3%82%8B%E3%83%87%E3%82%B8%E3%82%BF%E3%83%AB%E4%BF%A1%E5%8F%B7%E3%81%AF%E3%80%810%E3%81%A81%E3%81%AE%EF%BC%92%E5%80%A4%E3%81%97%E3%81%8B%E3%81%AA%E3%81%84%E3%81%AE%E3%81%A7%E3%80%81%E3%83%8E%E3%82%A4%E3%82%BA%E7%AD%89%E3%81%A7%E5%A4%89%E5%BD%A2%E3%81%97%E3%81%9F%E3%82%82%E3%81%AE%E3%82%92%E5%85%83%E3%81%AE%E3%81%8D%E3%82%8C%E3%81%84%E3%81%AA%EF%BC%92%E5%80%A4%E3%81%AE%E4%BF%A1%E5%8F%B7%E3%81%AB%E6%88%BB%E3%81%99%E3%81%93%E3%81%A8%E3%82%82%E5%8F%AF%E8%83%BD%E3%81%A8%E3%81%AA%E3%82%8A%E3%81%BE%E3%81%99%E3%80%82%20%E4%BE%8B%E3%81%88%E3%81%B0%E3%80%81%E5%AE%87%E5%AE%99%E3%81%8B%E3%82%89%E7%99%BA%E4%BF%A1%E3%81%97%E3%81%9F%E4%BF%A1%E5%8F%B7%E3%82%92%E5%9C%B0%E7%90%83%E4%B8%8A%E3%81%A7%E3%81%A8%E3%82%89%E3%81%88%E3%81%A6%E3%82%82%E3%82%B0%E3%83%8B%E3%83%A3%E3%82%B0%E3%83%8B%E3%83%A3%E3%81%AB%E3%81%AA%E3%81%A3%E3%81%A6%E3%81%97%E3%81%BE%E3%81%84%E3%81%BE%E3%81%99%E3%81%8C%E3%80%81%E3%81%93%E3%82%8C%E3%82%92%E5%85%83%E3%81%AE%EF%BC%92%E5%80%A4%E4%BF%A1%E5%8F%B7%E3%81%AB%E5%A4%89%E3%81%88%E3%82%8B%E3%81%8B%E3%82%89%E3%80%81%E7%A7%81%E3%81%9F%E3%81%A1%E3%81%AF%E3%80%81%E3%81%82%E3%81%9F%E3%81%8B%E3%82%82%E3%81%9D%E3%81%93%E3%81%AB%E3%81%84%E3%82%8B%E3%82%88%E3%81%86%E3%81%AB%E3%81%8D%E3%82%8C%E3%81%84%E3%81%AA%E7%94%BB%E5%83%8F,%E3%81%A7%E8%A6%8B%E3%82%8B%E3%81%93%E3%81%A8%E3%81%8C%E3%81%A7%E3%81%8D%E3%81%BE%E3%81%99%E3%80%82%E3%82%A2%E3%83%9D%E3%83%AD%EF%BC%91%EF%BC%91%E5%8F%B7%E3%81%8C%E6%9C%88%E3%81%AB%E7%9D%80%E9%99%B8%E3%81%97%E3%81%9F%E3%81%A8%E3%81%8D%E3%81%AF%E6%84%9F%E6%BF%80%E3%81%97%E3%81%BE%E3%81%97%E3%81%9F%E3%81%AD%E3%80%82))。0と1だけのデジタル信号は、ノイズが乗っても元の0か1に復元しやすいという利点もあり、コンピュータが正確かつ高速に情報を処理できる根幹となっています ([コンピュータが２進数を使うのはなぜ？ | なぜ？を科学する | アマノ科学教室](https://zai-amano.jp/why/binary/#:~:text=%E3%81%A4%E3%81%BE%E3%82%8A%E8%A1%A8%E3%81%AE%E3%82%88%E3%81%86%E3%81%AB%EF%BC%98%E6%9C%AC%E3%81%AE%E7%B7%9A%E3%81%8C%E3%81%82%E3%82%8C%E3%81%B0256%E3%81%AE%E7%B5%84%E3%81%BF%E5%90%88%E3%82%8F%E3%81%9B%E3%81%8C%E3%81%A7%E3%81%8D%E3%82%8B%E3%81%AE%E3%81%A7%E3%80%81%E3%82%AD%E3%83%BC%E3%83%9C%E3%83%BC%E3%83%89%E3%81%AE%E6%96%87%E5%AD%97%E3%82%92%E5%85%A8%E3%81%A6%E9%9B%BB%E6%B0%97%E4%BF%A1%E5%8F%B7%E3%81%A7%E8%A1%A8%E3%81%99%E3%81%93%E3%81%A8%E3%81%8C%E3%81%A7%E3%81%8D%E3%81%BE%E3%81%99%E3%80%82%E3%81%A0%E3%81%8B%E3%82%89%E3%80%81%E3%82%B3%E3%83%B3%E3%83%94%E3%83%A5%E3%83%BC%E3%82%BF%E3%81%AF0%E3%81%A81%E3%81%AE%E6%95%B0%E5%AD%97%E3%81%A7%E5%8A%B9%E7%8E%87%E3%82%88%E3%81%8F%20%E6%AD%A3%E7%A2%BA%E3%81%AB%E5%88%A4%E6%96%AD%E3%81%A7%E3%81%8D%E3%82%8B%E3%81%AE%E3%81%A7%E3%81%99%E3%80%82%20%E3%81%93%E3%81%AE0%E3%81%A81%E3%82%92%E3%83%93%E3%83%83%E3%83%88%EF%BC%88bit%EF%BC%89%E3%81%A8%E8%A8%80%E3%81%A3%E3%81%A6%E3%80%81%E3%82%B3%E3%83%B3%E3%83%94%E3%83%A5%E3%83%BC%E3%82%BF%E3%81%8C%E6%89%B1%E3%81%86%E6%9C%80%E5%B0%8F%E5%8D%98%E4%BD%8D%E3%81%A8%E3%81%AA%E3%82%8A%E3%81%BE%E3%81%99%E3%80%82%E3%81%BE%E3%81%9F%E3%80%810%E3%81%A81%E3%81%A7%E8%A1%A8%E3%81%95%E3%82%8C%E3%81%9F%E6%96%87%E5%AD%97%E3%82%84%E8%A8%98%E5%8F%B7%E3%82%92%E3%83%90%E3%82%A4%E3%83%8A%E3%83%AA%E3%83%BC%E3%83%87%E3%83%BC%E3%82%BF%EF%BC%88%EF%BC%92%E9%80%B2%E6%95%B0%E3%81%AE%E9%9B%86%E3%81%BE%E3%82%8A%EF%BC%89%E3%81%A8%E8%A8%80%E3%81%84%E3%81%BE%E3%81%99%E3%80%82%20%E3%81%93%E3%81%AE%EF%BC%92%E5%80%A4%E3%81%AE%E4%BF%A1%E5%8F%B7%E3%81%AB%E3%82%88%E3%81%A3%E3%81%A6%E5%87%A6%E7%90%86%E3%81%95%E3%82%8C%E3%81%A6%E3%81%84%E3%82%8B%E3%83%87%E3%82%B8%E3%82%BF%E3%83%AB%E4%BF%A1%E5%8F%B7%E3%81%AF%E3%80%810%E3%81%A81%E3%81%AE%EF%BC%92%E5%80%A4%E3%81%97%E3%81%8B%E3%81%AA%E3%81%84%E3%81%AE%E3%81%A7%E3%80%81%E3%83%8E%E3%82%A4%E3%82%BA%E7%AD%89%E3%81%A7%E5%A4%89%E5%BD%A2%E3%81%97%E3%81%9F%E3%82%82%E3%81%AE%E3%82%92%E5%85%83%E3%81%AE%E3%81%8D%E3%82%8C%E3%81%84%E3%81%AA%EF%BC%92%E5%80%A4%E3%81%AE%E4%BF%A1%E5%8F%B7%E3%81%AB%E6%88%BB%E3%81%99%E3%81%93%E3%81%A8%E3%82%82%E5%8F%AF%E8%83%BD%E3%81%A8%E3%81%AA%E3%82%8A%E3%81%BE%E3%81%99%E3%80%82%20%E4%BE%8B%E3%81%88%E3%81%B0%E3%80%81%E5%AE%87%E5%AE%99%E3%81%8B%E3%82%89%E7%99%BA%E4%BF%A1%E3%81%97%E3%81%9F%E4%BF%A1%E5%8F%B7%E3%82%92%E5%9C%B0%E7%90%83%E4%B8%8A%E3%81%A7%E3%81%A8%E3%82%89%E3%81%88%E3%81%A6%E3%82%82%E3%82%B0%E3%83%8B%E3%83%A3%E3%82%B0%E3%83%8B%E3%83%A3%E3%81%AB%E3%81%AA%E3%81%A3%E3%81%A6%E3%81%97%E3%81%BE%E3%81%84%E3%81%BE%E3%81%99%E3%81%8C%E3%80%81%E3%81%93%E3%82%8C%E3%82%92%E5%85%83%E3%81%AE%EF%BC%92%E5%80%A4%E4%BF%A1%E5%8F%B7%E3%81%AB%E5%A4%89%E3%81%88%E3%82%8B%E3%81%8B%E3%82%89%E3%80%81%E7%A7%81%E3%81%9F%E3%81%A1%E3%81%AF%E3%80%81%E3%81%82%E3%81%9F%E3%81%8B%E3%82%82%E3%81%9D%E3%81%93%E3%81%AB%E3%81%84%E3%82%8B%E3%82%88%E3%81%86%E3%81%AB%E3%81%8D%E3%82%8C%E3%81%84%E3%81%AA%E7%94%BB%E5%83%8F,%E3%81%A7%E8%A6%8B%E3%82%8B%E3%81%93%E3%81%A8%E3%81%8C%E3%81%A7%E3%81%8D%E3%81%BE%E3%81%99%E3%80%82%E3%82%A2%E3%83%9D%E3%83%AD%EF%BC%91%EF%BC%91%E5%8F%B7%E3%81%8C%E6%9C%88%E3%81%AB%E7%9D%80%E9%99%B8%E3%81%97%E3%81%9F%E3%81%A8%E3%81%8D%E3%81%AF%E6%84%9F%E6%BF%80%E3%81%97%E3%81%BE%E3%81%97%E3%81%9F%E3%81%AD%E3%80%82))。

**文字や画像の表現:** 数値だけでなく文字や画像も全て0と1のビット列に変換して扱われます。例えば文字は文字コード（ASCIIやUnicodeなど）によって数値に対応付けられ、画像は画素ごとの色を表す数値（RGB値など）の集合として2進数に変換されます。コンピュータ内部ではあらゆる種類のデータが2進数として統一的に表現・格納されます。

### ハードウェアの基本構成（5大装置）

コンピュータは基本的に**入力装置**・**出力装置**・**記憶装置**・**制御装置**・**演算装置**の「5大装置」から構成されています ([コンピュータの５大装置とCPU・メモリの役割 │ Pei's Lab](https://peislab.com/programming/introduction/cpu-memory/#:~:text=Image))。制御装置と演算装置を合わせたものが**中央処理装置（CPU）**です。図 ([コンピュータの５大装置とCPU・メモリの役割 │ Pei's Lab](https://peislab.com/programming/introduction/cpu-memory/))はコンピュータの典型的な構成を示したものです。人間が与えるデータはキーボードやマウス、センサなどの入力装置からコンピュータに入り、まず主記憶装置（メモリ）に格納されます。プログラムの命令や変数もすべて主記憶上に配置されます。

 ([コンピュータの５大装置とCPU・メモリの役割 │ Pei's Lab](https://peislab.com/programming/introduction/cpu-memory/))  
*図1: コンピュータの5大装置の構成図（入力装置、出力装置、記憶装置（主記憶・補助記憶）、制御装置、演算装置）。制御装置と演算装置を合わせてCPUと呼ぶ。主記憶（RAM）にプログラムとデータが格納され、CPUがそれらを読み出して順次処理を実行する。 ([コンピュータの５大装置とCPU・メモリの役割 │ Pei's Lab](https://peislab.com/programming/introduction/cpu-memory/#:~:text=Image))【60†L13-L20}*

CPUの制御装置は**主記憶装置（メモリ）から命令を取り出し（フェッチ）** ([コンピュータの５大装置とCPU・メモリの役割 │ Pei's Lab](https://peislab.com/programming/introduction/cpu-memory/#:~:text=match%20at%20L125%20%E3%81%93%E3%81%AE%E3%80%8C%E5%88%B6%E5%BE%A1%E8%A3%85%E7%BD%AE%E3%81%8C%E5%91%BD%E4%BB%A4%E3%82%92%E3%83%A1%E3%83%A2%E3%83%AA%E3%81%8B%E3%82%89%E8%AA%AD%E3%81%BF%E8%BE%BC%E3%82%80%E5%8B%95%E4%BD%9C%E3%80%8D%E3%82%92%E3%83%95%E3%82%A7%E3%83%83%E3%83%81%20%E3%81%A8%E8%A8%80%E3%81%84%E3%81%BE%E3%81%99%E3%80%82))、**命令を解読して何をすべきか判断し（デコード）** ([コンピュータの５大装置とCPU・メモリの役割 │ Pei's Lab](https://peislab.com/programming/introduction/cpu-memory/#:~:text=match%20at%20L140%20%E3%83%95%E3%82%A7%E3%83%83%E3%83%81%E3%81%97%E3%81%9F%E3%83%87%E3%83%BC%E3%82%BF))、演算装置などに指示を与えてその命令を**実行（実行ステージ）**します ([コンピュータの５大装置とCPU・メモリの役割 │ Pei's Lab](https://peislab.com/programming/introduction/cpu-memory/#:~:text=%E3%83%95%E3%82%A7%E3%83%83%E3%83%81%E3%81%97%E3%81%9F%E3%83%87%E3%83%BC%E3%82%BF))。この**フェッチ→デコード→実行**のサイクルを高速に繰り返すことで、プログラムに書かれた一連の処理が次々と実行されます ([コンピュータの５大装置とCPU・メモリの役割 │ Pei's Lab](https://peislab.com/programming/introduction/cpu-memory/#:~:text=CPU%E3%81%AE%E3%83%9D%E3%82%A4%E3%83%B3%E3%83%88%E3%81%AF%20%E3%83%95%E3%82%A7%E3%83%83%E3%83%81%E2%86%92%E3%83%87%E3%82%B3%E3%83%BC%E3%83%89%E2%86%92%E5%AE%9F%E8%A1%8C%E3%81%AE%E9%A0%86%E3%81%A7%E5%87%A6%E7%90%86%E3%82%92%E7%B9%B0%E3%82%8A%E8%BF%94%E3%81%99%20%E3%81%A8%E8%A8%80%E3%81%86%E3%81%93%E3%81%A8%E3%81%A7%E3%81%99%E3%80%82%E8%A8%80%E8%91%89%E3%81%AE%E8%AA%AC%E6%98%8E%E3%81%A0%E3%81%A8%E7%90%86%E8%A7%A3%E3%81%8C%E9%9B%A3%E3%81%97%E3%81%84%E3%81%AE%E3%81%A7%E3%80%81%E5%85%B7%E4%BD%93%E7%9A%84%E3%81%AA%E4%BE%8B%E3%82%92%E7%94%A8%E3%81%84%E3%81%A6%E8%AA%AC%E6%98%8E%E3%82%82%E3%81%97%E3%81%BE%E3%81%99%E3%80%82%E5%89%8D%E5%8D%8A%E3%81%AF%E6%A6%82%E5%BF%B5%E7%9A%84%E3%81%AA%E8%AA%AC%E6%98%8E%E3%81%A0%E3%81%91%E3%81%A7%E9%80%80%E5%B1%88%E3%81%A7%E3%81%99%E3%81%8C%E9%A0%91%E5%BC%B5%E3%81%A3%E3%81%A6%E8%80%90%E3%81%88%E3%81%A6%E3%81%8F%E3%81%A0%E3%81%95%E3%81%84%E3%80%82)) ([コンピュータの５大装置とCPU・メモリの役割 │ Pei's Lab](https://peislab.com/programming/introduction/cpu-memory/#:~:text=match%20at%20L159%20%E5%AE%9F%E8%A1%8C%E3%81%8C%E5%AE%8C%E4%BA%86%E3%81%97%E3%81%9F%E3%82%89%E6%AC%A1%E3%81%AE%E5%91%BD%E4%BB%A4%E3%81%8C%E3%83%95%E3%82%A7%E3%83%83%E3%83%81%E3%81%95%E3%82%8C%E3%80%81%E3%83%87%E3%82%B3%E3%83%BC%E3%83%89%E3%80%81%E5%AE%9F%E8%A1%8C%E3%81%A8%E5%87%A6%E7%90%86%E3%82%92%E7%B9%B0%E3%82%8A%E8%BF%94%E3%81%97%E3%81%BE%E3%81%99%E3%80%82CPU%E3%81%AE%E5%87%A6%E7%90%86%E5%8A%B9%E7%8E%87%E3%82%92%E4%B8%8A%E3%81%92%E3%82%8B%E3%81%9F%E3%82%81%E3%81%AB%E3%80%81%E3%83%87%E3%82%B3%E3%83%BC%E3%83%89%E4%B8%AD%E3%82%84%E5%AE%9F%E8%A1%8C%E4%B8%AD%E3%81%AB%E6%AC%A1%E3%81%AE%E5%91%BD%E4%BB%A4%E3%81%AE%E3%83%95%E3%82%A7%E3%83%83%E3%83%81%E3%82%92%E4%B8%A6%E8%A1%8C%E3%81%97%E3%81%A6%E8%A1%8C%E3%81%AA%20%E3%81%86%E3%83%91%E3%82%A4%E3%83%97%E3%83%A9%E3%82%A4%E3%83%B3%E5%87%A6%E7%90%86%E3%81%A8%E3%81%84%E3%81%86%E3%82%82%E3%81%AE%E3%82%92%E5%AE%9F%E8%A3%85%E3%81%97%E3%81%9F%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E3%82%82%E3%81%82%E3%82%8A%E3%81%BE%E3%81%99%E3%80%82))。CPU内部には一時的にデータを保持する**レジスタ**と呼ばれる小さな記憶装置も含まれ、演算装置はレジスタ上のデータに対して加減乗除などの計算を行います ([コンピュータの５大装置とCPU・メモリの役割 │ Pei's Lab](https://peislab.com/programming/introduction/cpu-memory/#:~:text=%E5%9B%B3%E3%81%AE%E4%B8%AD%E3%81%AE%E3%80%8C%E5%85%A5%E5%8A%9B%E8%A3%85%E7%BD%AE%E3%80%8D%E3%80%8C%E8%A8%98%E6%86%B6%E8%A3%85%E7%BD%AE%E3%80%8D%E3%80%8C%E5%88%B6%E5%BE%A1%E8%A3%85%E7%BD%AE%E3%80%8D%E3%80%8C%E6%BC%94%E7%AE%97%E8%A3%85%E7%BD%AE%E3%80%8D%E3%80%8C%E5%87%BA%E5%8A%9B%E8%A3%85%E7%BD%AE%E3%80%8D%E3%81%8C%EF%BC%95%E5%A4%A7%E8%A3%85%E7%BD%AE%E3%81%A8%E5%91%BC%E3%81%B0%E3%82%8C%E3%81%A6%E3%81%84%E3%81%BE%E3%81%99%E3%80%82))。主記憶装置（RAM）は電源を切ると内容が消えてしまうため、長期的なデータ保存には**補助記憶装置**（HDDやSSDなど）を用います ([コンピュータの５大装置とCPU・メモリの役割 │ Pei's Lab](https://peislab.com/programming/introduction/cpu-memory/#:~:text=%E5%9B%B3%E3%81%AE%E4%B8%AD%E3%81%AE%E3%80%8C%E5%85%A5%E5%8A%9B%E8%A3%85%E7%BD%AE%E3%80%8D%E3%80%8C%E8%A8%98%E6%86%B6%E8%A3%85%E7%BD%AE%E3%80%8D%E3%80%8C%E5%88%B6%E5%BE%A1%E8%A3%85%E7%BD%AE%E3%80%8D%E3%80%8C%E6%BC%94%E7%AE%97%E8%A3%85%E7%BD%AE%E3%80%8D%E3%80%8C%E5%87%BA%E5%8A%9B%E8%A3%85%E7%BD%AE%E3%80%8D%E3%81%8C%EF%BC%95%E5%A4%A7%E8%A3%85%E7%BD%AE%E3%81%A8%E5%91%BC%E3%81%B0%E3%82%8C%E3%81%A6%E3%81%84%E3%81%BE%E3%81%99%E3%80%82))。

ポイントは、コンピュータは自ら判断して動くのではなく**「与えられた命令を順に実行するだけ」**ということです ([今さら聞けない！コンピュータの“アルゴリズム”って何？ | TECHのススメ](https://haa.athuman.com/media/it/programming/982/#:~:text=%E2%91%A0%20%E4%BA%BA%E9%96%93%E3%81%8B%E3%82%89%E4%B8%8E%E3%81%88%E3%82%89%E3%82%8C%E3%81%9F%E3%83%87%E3%83%BC%E3%82%BF%E3%82%92%E8%A8%98%E6%86%B6%E3%81%99%E3%82%8B))。例えば「データを記憶する」「計算する」「条件によって処理を分岐する（条件分岐）」「一定の処理を繰り返す（ループ）」「別のコンピュータと通信する」といった操作しかできず ([今さら聞けない！コンピュータの“アルゴリズム”って何？ | TECHのススメ](https://haa.athuman.com/media/it/programming/982/#:~:text=%E2%91%A0%20%E4%BA%BA%E9%96%93%E3%81%8B%E3%82%89%E4%B8%8E%E3%81%88%E3%82%89%E3%82%8C%E3%81%9F%E3%83%87%E3%83%BC%E3%82%BF%E3%82%92%E8%A8%98%E6%86%B6%E3%81%99%E3%82%8B))、その内容もすべて人間が用意したプログラムに沿ったものです。コンピュータは確かに高速かつ正確に計算できますが、それ自体に創造的な能力はなく、人間の指示（プログラム）に従って動作する**「道具」**だと言えます。

### ソフトウェアとプログラミング言語

コンピュータに命令を与えるには、本来**機械語**と呼ばれる0と1のビット列で書かれた命令コードをメモリに配置する必要があります。しかし、人間にとって機械語のビット列を直接扱うのは非常に難しいため、実用上は**高水準のプログラミング言語**を用いて記述します。例えば、C言語やJava、Pythonなどのプログラミング言語で人間が理解しやすいソースコードを書き、それを機械語に変換して実行する仕組みを取ります。高級言語で書かれたプログラムは、**コンパイラ**という翻訳プログラムによって機械語（CPUが理解できる命令列）に変換されるか、あるいは**インタプリタ**と呼ばれる実行環境によって逐次解釈・実行されます ([コンピュータの５大装置とCPU・メモリの役割 │ Pei's Lab](https://peislab.com/programming/introduction/cpu-memory/#:~:text=%E3%81%95%E3%81%A6%E3%80%81%E4%B8%80%E9%80%A3%E3%81%AE%E6%B5%81%E3%82%8C%E3%82%92%E8%A6%8B%E3%81%A6%E3%81%84%E3%81%8D%E3%81%BE%E3%81%97%E3%82%87%E3%81%86%E3%80%82%E5%87%A6%E7%90%86%E3%81%8C%E9%95%B7%E3%81%84%E3%81%AE%E3%81%A7%E5%8B%95%E7%94%BB%E3%81%AB%E3%81%97%E3%81%BE%E3%81%97%E3%81%9F%E3%80%82%E9%81%A9%E5%AE%9C%E5%81%9C%E6%AD%A2%E3%81%97%E3%81%AA%E3%81%8C%E3%82%89%E7%A2%BA%E8%AA%8D%E3%81%97%E3%81%A6%E3%81%8F%E3%81%A0%E3%81%95%E3%81%84%E3%80%82%E3%83%95%E3%82%A7%E3%83%83%E3%83%81%E3%81%A7PC%E3%81%8C%E6%8C%87%E3%81%99%E3%82%A2%E3%83%89%E3%83%AC%E3%82%B9%E3%81%AE%E5%80%A4%E3%82%92%E3%83%87%E3%82%B3%E3%83%BC%E3%83%80%E3%81%AB%E6%B8%A1%E3%81%97%E3%80%81%E3%83%87%E3%82%B3%E3%83%BC%E3%83%80%E3%81%8C%20%E3%83%87%E3%82%B3%E3%83%BC%E3%83%89%E3%81%97%E3%80%81%E5%AE%9F%E8%A1%8C%E3%81%A7%E6%B1%8E%E7%94%A8%E3%83%AC%E3%82%B8%E3%82%B9%E3%82%BF%E3%82%84%E3%83%A1%E3%83%A2%E3%83%AA%E3%81%AE%E5%80%A4%E3%82%92%E6%9B%B4%E6%96%B0%E3%81%97%E3%81%A6%E3%81%84%E3%82%8B%20%E3%81%93%E3%81%A8%E3%81%AB%E7%9D%80%E7%9B%AE%E3%81%97%E3%81%A6%E3%81%8F%E3%81%A0%E3%81%95%E3%81%84%E3%80%82%E4%BA%8C%E9%80%B2%E6%95%B0%E3%81%A7%E6%9B%B8%E3%81%8B%E3%82%8C%E3%81%A6%E3%81%84%E3%82%8B%E5%91%BD%E4%BB%A4%E3%81%AE%E6%96%87%E6%B3%95%E3%81%AFCPU%E4%BE%9D%E5%AD%98%E3%81%AA%E3%81%AE%E3%81%A7%E7%89%B9%E3%81%AB%E7%90%86%E8%A7%A3%E3%81%99%E3%82%8B%E5%BF%85%E8%A6%81%E3%81%AF%E3%81%82%E3%82%8A%E3%81%BE%E3%81%9B%E3%82%93%E3%80%82%20%E3%83%87%E3%82%B3%E3%83%BC%E3%83%89%E5%BE%8C%E3%81%AE%E5%87%A6%E7%90%86%E5%86%85%E5%AE%B9%E3%82%92%E8%A8%98%E8%BC%89%E3%81%97%E3%81%A6%E3%81%84%E3%82%8B%E3%81%AE%E3%81%A7%E3%80%81%E5%90%84%E5%91%BD%E4%BB%A4%E3%81%A7%E4%BD%95%E3%82%92%E3%81%99%E3%82%8B%E3%81%AE%E3%81%8B%E3%82%92%E7%90%86%E8%A7%A3%E3%81%97%E3%81%A6%E3%81%8F%E3%81%A0%E3%81%95%E3%81%84%E3%80%82%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0%E8%A8%80%E8%AA%9E%E3%81%A7%E3%81%AF%E6%95%B0%E8%A1%8C%E3%81%A7%E6%9B%B8%E3%81%8B%E3%82%8C%E3%82%8B%E5%87%A6%E7%90%86%E3%81%8C%E3%80%81%E7%B4%B0%E5%88%86%E5%8C%96%E3%81%95%E3%82%8C%E3%81%A6CPU%E3%81%8C%E8%A8%88%E7%AE%97%E3%81%A7%E3%81%8D%E3%82%8B%E7%B2%92%E5%BA%A6%E3%81%AB%20%E3%81%95%E3%82%8C%E3%81%A6%E3%81%84%E3%82%8B%E3%81%AE%E3%81%8C%E3%82%8F%E3%81%8B%E3%82%8B%E3%81%A8%E6%80%9D%E3%81%84%E3%81%BE%E3%81%99%E3%80%82%E3%81%A1%E3%81%AA%E3%81%BF%E3%81%AB%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0%E8%A8%80%E8%AA%9E%E3%82%92%E3%81%93%E3%81%AE%E5%91%BD%E4%BB%A4%E3%81%AB%E5%A4%89%E6%8F%9B%E3%81%99%E3%82%8B%E4%BD%9C%E6%A5%AD%E3%81%93%E3%81%9D%E3%81%8C%E3%82%B3%E3%83%B3%E3%83%91%E3%82%A4%E3%83%AB%E3%81%A7%E3%81%99%E3%80%82))。このように、プログラミング言語→機械語への変換を経てCPUが命令を実行することで、人間の意図した処理がコンピュータ上で実現されます。

**例：簡単なプログラムの実行** – 以下にPythonで書いた簡単なプログラムの例を示します。このコードは整数を2進数の文字列に変換するものです（Pythonには組み込み関数`bin()`もありますが、アルゴリズムの例として自前の関数を定義しています）。

```python
def to_binary(n):
    bits = []
    while n > 0:
        bits.append(str(n % 2))
        n //= 2
    return ''.join(reversed(bits))

print(to_binary(11))  # 10進数11を2進数に変換
```

このプログラムを実行すると、期待通り`1011`という結果が表示されます。これは先ほど述べたように10進数の11を2進数で表した値です ([コンピュータが２進数を使うのはなぜ？ | なぜ？を科学する | アマノ科学教室](https://zai-amano.jp/why/binary/#:~:text=%E3%81%A4%E3%81%BE%E3%82%8A10%E9%80%B2%E6%95%B0%E3%81%AE11%E3%82%922%E9%80%B2%E6%95%B0%E3%81%A7%E8%A1%A8%E3%81%99%E3%81%A81011%E3%81%A8%E3%81%AA%E3%82%8A%E3%81%BE%E3%81%99%E3%80%82))。この例では、`while`ループを用いて整数を2で割り続けるアルゴリズムによって、下位ビットから順に求めた結果をリストに追加し、最後に順番を反転して2進数文字列を得ています。プログラミング言語を使うことで、人間は機械語を直接意識せずともアルゴリズムを実装できます。そしてコンパイラ/インタプリタがそのコードを解釈し、CPUが実行することで、コンピュータに問題解決の手順を遂行させることができるのです。

### アルゴリズムと問題解決

問題を解くための手順を定めたものを**アルゴリズム**と呼びます。アルゴリズムは「ある問題を解決するための一連の明確な手続き」です ([アルゴリズムとは？ 意味や使い方、具体例をわかりやすく解説｜SmartCompany（スマカン）](https://smartcompany.jp/column/algorithm/#:~:text=%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0%E3%81%A8%E3%81%AF%EF%BC%9F))。プログラムはアルゴリズムを具体的にコード化（実装）したものと言えます。アルゴリズムが適切でないと、プログラムは正しく動作しなかったり無駄に時間がかかったりします ([今さら聞けない！コンピュータの“アルゴリズム”って何？ | TECHのススメ](https://haa.athuman.com/media/it/programming/982/#:~:text=%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0%EF%BC%88algorithm%EF%BC%89%E3%81%A8%E3%81%AF%E3%80%81%E5%95%8F%E9%A1%8C%E3%82%92%E8%A7%A3%E3%81%8F%E3%81%9F%E3%82%81%E3%81%AE%E6%89%8B%E9%A0%86%E3%81%AE%E3%81%93%E3%81%A8%E3%81%A7%E3%81%99%E3%80%82%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0%E3%81%8C%E3%82%B3%E3%83%B3%E3%83%94%E3%83%A5%E3%83%BC%E3%82%BF%E3%82%92%E5%8B%95%E4%BD%9C%E3%81%95%E3%81%9B%E3%82%8B%E3%81%AE%E3%81%AB%E9%87%8D%E8%A6%81%E3%81%A7%E3%81%82%E3%82%8B%E3%81%93%E3%81%A8%E3%81%AF%E5%85%88%E3%81%BB%E3%81%A9%E8%AA%AC%E6%98%8E%E3%81%97%E3%81%BE%E3%81%97%E3%81%9F%E3%80%82%E3%81%9D%E3%81%AE%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%20%E3%83%A0%E3%81%8C%E6%A7%98%E3%80%85%E3%81%AA%E3%83%87%E3%83%BC%E3%82%BF%E3%82%92%E5%87%A6%E7%90%86%E3%81%99%E3%82%8B%E3%82%8F%E3%81%91%E3%81%A7%E3%81%99%E3%81%8C%E3%80%81%E3%81%9D%E3%81%AE%E6%89%8B%E9%A0%86%E3%81%8C%E6%82%AA%E3%81%91%E3%82%8C%E3%81%B0%E6%99%82%E9%96%93%E3%81%8C%E6%8E%9B%E3%81%8B%E3%81%A3%E3%81%9F%E3%82%8A%E3%80%81%E9%96%93%E9%81%95%E3%81%A3%E3%81%9F%E3%81%93%E3%81%A8%E3%81%8C%E8%B5%B7%E3%81%8D%E3%81%9F%E3%82%8A%E3%81%99%E3%82%8B%E5%8F%AF%E8%83%BD%E6%80%A7%E3%81%8C%E5%A2%97%E3%81%88%E3%81%BE%E3%81%99%E3%80%82))。逆に、良いアルゴリズムは限られた資源で効率よく問題を解決できます。

例えば、**数列を小さい順に並べ替える（ソートする）**問題を考えてみましょう。最も素朴なアルゴリズムの一つに「バブルソート」があります。バブルソートでは、隣り合う要素を比較して順序が逆なら交換する操作を配列の端から端まで繰り返し、これを全体がソート済みになるまで何度も実行します。明確な手順として書けば以下のようになります。

1. 配列の先頭から隣同士の要素を順に比較する  
2. 前の要素が後の要素より大きければ2つを交換する  
3. 配列末尾までこの比較・交換を繰り返すと、最大要素が末尾に泡（バブル）のように移動する  
4. 同様の操作を残りの部分について繰り返す  

この**バブルソート**もアルゴリズムの一種であり、プログラムに実装すればコンピュータが高速に正確に実行してくれます ([今さら聞けない！コンピュータの“アルゴリズム”って何？ | TECHのススメ](https://haa.athuman.com/media/it/programming/982/#:~:text=Image))。しかし、バブルソートより効率の良いソートアルゴリズム（例えばクイックソートなど）も存在します。「より少ない手順で問題を解く方法を考案すること」がアルゴリズム研究の醍醐味であり、コンピュータサイエンスの中心的な課題です。

**計算量の概念:** アルゴリズムの良し悪しは問題の規模に対する**計算量の増え方**で評価できます。入力サイズを$n$としたとき、処理に要する計算ステップが$n$に比例する場合は**線形時間**、$n^2$に比例する場合は**二乗時間**といった具合に表現します。一般に、計算量が多項式程度に抑えられるアルゴリズムは実用的ですが、指数関数的に増大するアルゴリズムは入力が少し大きくなるだけで現実的時間内に終わらなくなります。このように効率も考慮しながら、問題を正しく解く手順を設計・分析することがコンピュータサイエンスの基礎と言えるでしょう。

### まとめ

第1章では、コンピュータの基本原理とプログラミングの初歩について解説しました。コンピュータは0と1からなるデジタル信号でデータを扱い、CPUがプログラムの命令を順次実行することで動作します。人間は高水準のプログラミング言語を用いてアルゴリズム（手順）を記述し、コンパイルや実行を経てコンピュータに問題解決をさせます。コンピュータサイエンスの第一歩として、情報の2進数表現やハードウェア構成、そしてアルゴリズムとプログラミングの基礎を押さえることができました。

## 第2章：機械学習に必要な数学

機械学習を本格的に学ぶには、基礎となる数学の理解が不可欠です。本章では**微分**・**線形代数**・**確率統計**という三つの分野から、機械学習に特に重要なポイントを解説します ([機械学習に数学の知識は必要？最低限の基礎知識を徹底解説 - doda](https://doda.jp/engineer/guide/it/052.html#:~:text=%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%81%AB%E6%95%B0%E5%AD%A6%E3%81%AE%E7%9F%A5%E8%AD%98%E3%81%AF%E5%BF%85%E8%A6%81%EF%BC%9F%E6%9C%80%E4%BD%8E%E9%99%90%E3%81%AE%E5%9F%BA%E7%A4%8E%E7%9F%A5%E8%AD%98%E3%82%92%E5%BE%B9%E5%BA%95%E8%A7%A3%E8%AA%AC%20)) ([【AI】なんで線形代数はプログラミングに大事？気になる機械学習](https://www.geekly.co.jp/column/cat-technology/1902_049/#:~:text=AI%20%E3%81%AA%E3%82%93%E3%81%A7%E7%B7%9A%E5%BD%A2%E4%BB%A3%E6%95%B0%E3%81%AF%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0%E3%81%AB%E5%A4%A7%E4%BA%8B%EF%BC%9F%E6%B0%97%E3%81%AB%E3%81%AA%E3%82%8B%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%20%E7%B7%9A%E5%BD%A2%E4%BB%A3%E6%95%B0%E3%82%84%E5%BE%AE%E5%88%86%E7%A9%8D%E5%88%86%E3%81%AA%E3%81%A9%E3%81%AFAI%E3%81%AE%E4%BB%95%E7%B5%84%E3%81%BF%E3%81%AB%E3%81%8A%E3%81%84%E3%81%A6%E9%87%8D%E8%A6%81%E3%81%AA%E3%82%82%E3%81%AE%E3%81%A7%E3%81%97%E3%81%9F%E3%81%8C%E3%80%81%E7%A2%BA%E7%8E%87%E3%82%84%E7%B5%B1%E8%A8%88%E3%81%AB%E9%96%A2%E3%81%99%E3%82%8B%E6%95%B0%E5%AD%A6%E7%9A%84%E7%9F%A5%E8%AD%98%E3%82%82AI%E9%96%8B%E7%99%BA%E3%81%AB%E3%81%AF%E5%BF%85%E9%A0%88%E3%81%A7%E3%81%99%E3%80%82%E3%81%93%E3%81%A1%E3%82%89%E3%81%AF%E3%81%AA%E3%82%93%E3%81%A8%E3%81%AA%E3%81%8F%E3%82%A4%E3%83%A1%E3%83%BC%E3%82%B8%20))。数式に苦手意識がある人もいるかもしれませんが、できるだけ丁寧に説明していきます。これらの数学的道具を身につけることで、機械学習アルゴリズムの仕組みがより直感的に理解できるようになるでしょう。

### 微分積分の基礎

**微分**とは、関数の変化の割合を表す概念です。簡単な例として、一次関数 $y = ax + b$ の傾きは常に一定で $a$ ですが、一般の関数では場所によって傾き（変化率）が異なります。ある関数 $f(x)$ において、ある点$x$付近での変化の割合（接線の傾き）を表すのが**微分係数**であり、これを求める操作を「微分する」と言います。微分係数は極限操作で定義されますが、基本的な関数については以下のような公式が知られています ([1. 機械学習に必要な数学の基礎 — メディカルAI専門コース オンライン講義資料  documentation](https://japan-medical-ai.github.io/medical-ai-course-materials/notebooks/01_Basic_Math_for_ML.html#:~:text=1))（$c$は定数）:

- $(x^n)' = n x^{n-1}$  （べき乗の微分）  
- $(\sin x)' = \cos x$, $(\cos x)' = -\sin x$  （三角関数の微分）  
- $(e^x)' = e^x$  （指数関数の微分）  など

複数の関数が合成された場合（例えば$f(x) = (3x+4)^2$など）、**合成関数の微分**では**チェインルール（連鎖律）**を適用します ([1. 機械学習に必要な数学の基礎 — メディカルAI専門コース オンライン講義資料  documentation](https://japan-medical-ai.github.io/medical-ai-course-materials/notebooks/01_Basic_Math_for_ML.html#:~:text=match%20at%20L176%20%E5%BE%AE%E5%88%86%E3%81%A7%E3%81%99%EF%BC%8E%E5%85%88%E7%A8%8B%E7%B4%B9%E4%BB%8B%E3%81%97%E3%81%9F%E5%BE%AE%E5%88%86%E3%81%AE%E5%85%AC%E5%BC%8F%E3%81%AE%E6%9C%80%E5%BE%8C%E3%81%AB%E7%99%BB%E5%A0%B4%E3%81%97%E3%81%A6%E3%81%84%E3%81%9F%E5%BC%8F%E3%81%A7%E3%81%99%EF%BC%8E%E5%90%88%E6%88%90%E9%96%A2%E6%95%B0%E3%81%AE%E5%BE%AE%E5%88%86%E3%81%AF%EF%BC%8C%E5%86%85%E5%81%B4%E3%81%AE%E5%BE%AE%E5%88%86%E3%81%A8%E5%A4%96%E5%81%B4%E3%81%AE%E5%BE%AE%E5%88%86%E3%82%92%E3%81%9D%E3%82%8C%E3%81%9E%E3%82%8C%E8%A1%8C%E3%81%84%EF%BC%8C%E3%81%9D%E3%81%AE%E7%B5%90%E6%9E%9C%E3%82%92%E3%81%8B%E3%81%91%E5%90%88%E3%82%8F%E3%81%9B%E3%82%8B%E3%81%93%E3%81%A8%E3%81%A7%E6%B1%82%E3%82%81%E3%82%8B%E3%81%93%E3%81%A8%E3%81%8C%E3%81%A7%E3%81%8D%20%E3%81%BE%E3%81%99%EF%BC%8E%E5%A4%96%E5%81%B4%E3%81%AE%E5%BE%AE%E5%88%86%E3%81%AE%E9%9A%9B%E3%81%AB%E3%81%AF%E9%96%A2%E6%95%B0%E3%81%AE%E5%BC%95%E6%95%B0%E3%82%92%E5%85%A5%E5%8A%9B%E3%81%A8%E3%81%BF%E3%81%AA%E3%81%97%EF%BC%8C%E3%81%9D%E3%81%AE%E5%85%A5%E5%8A%9B%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6%E5%BE%AE%E5%88%86%E3%82%92%E3%81%A8%E3%82%8A%E3%81%BE%E3%81%99%EF%BC%8E))。チェインルールとは「外側の関数を微分し、内側の関数の微分を掛け合わせる」というものです。先ほどの例$f(x)=(3x+4)^2$にチェインルールを使うと、まず外側$(u^2)'=2u$に対し$u=3x+4$を代入して$2(3x+4)$、次に内側$(3x+4)'=3$を掛けて結果は$f'(x)=2(3x+4)\times 3 = 6(3x+4)$となります。

機械学習では、後述するようにモデルの最適化で微分（傾き）が重要な役割を果たします。特にモデルの誤差（損失関数）を微分して最小となる点を探す**勾配降下法**では、関数の傾き＝0となる点（停留点）を見つけることが目標になります。微分の公式をしっかり押さえておけば、複雑なモデルの最適化問題も解きやすくなるでしょう。

**偏微分と勾配:** 通常の微分は一変数の関数に対する操作ですが、機械学習ではしばしば**多変数関数**を扱います。例えば入力が複数特徴$(x_1, x_2, \dots, x_M)$から成り出力$y$を予測するモデルは、$y = f(x_1,x_2,\dots,x_M)$という関数で表せます ([1. 機械学習に必要な数学の基礎 — メディカルAI専門コース オンライン講義資料  documentation](https://japan-medical-ai.github.io/medical-ai-course-materials/notebooks/01_Basic_Math_for_ML.html#:~:text=1))。こうした多変数関数において、ある一つの変数$x_m$に着目して他の変数を一定とみなして行う微分を**偏微分**といいます ([1. 機械学習に必要な数学の基礎 — メディカルAI専門コース オンライン講義資料  documentation](https://japan-medical-ai.github.io/medical-ai-course-materials/notebooks/01_Basic_Math_for_ML.html#:~:text=match%20at%20L203%20x_M%29,%E3%81%A8%E3%82%88%E3%81%B3%EF%BC%8C))。偏微分の記法は例えば$x_m$についての偏微分を $\frac{\partial}{\partial x_m}f(x_1,\ldots,x_M)$ と書きます ([1. 機械学習に必要な数学の基礎 — メディカルAI専門コース オンライン講義資料  documentation](https://japan-medical-ai.github.io/medical-ai-course-materials/notebooks/01_Basic_Math_for_ML.html#:~:text=x_M%29))。

偏微分も通常の微分と同じ公式で計算できます。ただし他の変数は定数扱いする点が異なります ([1. 機械学習に必要な数学の基礎 — メディカルAI専門コース オンライン講義資料  documentation](https://japan-medical-ai.github.io/medical-ai-course-materials/notebooks/01_Basic_Math_for_ML.html#:~:text=%E5%81%8F%E5%BE%AE%E5%88%86%E3%81%A7%E3%82%82%E5%BE%AE%E5%88%86%E3%81%A8%E5%90%8C%E3%81%98%E5%85%AC%E5%BC%8F%E3%82%92%E9%81%A9%E7%94%A8%E3%81%A7%E3%81%8D%E3%81%BE%E3%81%99%EF%BC%8E%E4%BB%8A%E5%9B%9E%E3%81%AE%E3%82%B1%E3%83%BC%E3%82%B9%E3%81%A7%E3%81%AF%EF%BC%8C%5C%28x_))。例えば $f(x_1,x_2)=3x_1 + 4x_2$ の場合、$x_1$による偏微分$\partial f/\partial x_1$は$x_2$を定数として扱うので結果は3になります。一方、$\partial f/\partial x_2$は結果4になります。これら各変数についての偏微分を成分に並べたベクトルを**勾配（gradient）**と呼びます ([1. 機械学習に必要な数学の基礎 — メディカルAI専門コース オンライン講義資料  documentation](https://japan-medical-ai.github.io/medical-ai-course-materials/notebooks/01_Basic_Math_for_ML.html#:~:text=%E5%BE%AE%E5%88%86%E3%81%AF%E5%85%A5%E5%8A%9B%E3%82%92%E5%A4%89%E3%81%88%E3%81%9F%E5%A0%B4%E5%90%88%E3%81%AE%E9%96%A2%E6%95%B0%E5%80%A4%E3%81%AE%E5%A4%89%E5%8C%96%E9%87%8F%E3%81%A8%E8%AA%AC%E6%98%8E%E3%81%97%E3%81%BE%E3%81%97%E3%81%9F%EF%BC%8E%E5%90%8C%E6%A7%98%E3%81%AB%E9%96%A2%E6%95%B0%E3%81%AE%E5%85%A5%E5%8A%9B%E3%81%8C%E3%83%99%E3%82%AF%E3%83%88%E3%83%AB%E3%81%A7%E3%81%82%E3%82%8B%E5%A0%B4%E5%90%88%EF%BC%8C%E3%83%99%E3%82%AF%E3%83%88%E3%83%AB%E3%81%AB%E3%82%88%E3%82%8B%E5%BE%AE%E5%88%86%E3%82%92%E8%80%83%E3%81%88%E3%82%8B%E3%81%93%E3%81%A8%E3%81%8C%E3%81%A7%E3%81%8D%E3%81%BE%E3%81%99%EF%BC%8E%E9%96%A2%E6%95%B0%E3%81%AE%E3%81%9D%E3%82%8C%E3%81%9E%E3%82%8C%E3%81%AE%E3%83%99%E3%82%AF%E3%83%88%E3%83%AB%E3%81%AE%20%E6%88%90%E5%88%86%E6%AF%8E%E3%81%AB%E5%81%8F%E5%BE%AE%E5%88%86%E3%82%92%E8%A8%88%E7%AE%97%E3%81%97%EF%BC%8C%E3%81%9D%E3%82%8C%E3%82%89%E3%82%92%E4%B8%A6%E3%81%B9%E3%81%A6%E3%83%99%E3%82%AF%E3%83%88%E3%83%AB%E3%81%AB%E3%81%97%E3%81%9F%E3%82%82%E3%81%AE%E3%82%92%20%E5%8B%BE%E9%85%8D%20%E3%81%A8%E3%82%88%E3%81%B3%E3%81%BE%E3%81%99%EF%BC%8E)) ([1. 機械学習に必要な数学の基礎 — メディカルAI専門コース オンライン講義資料  documentation](https://japan-medical-ai.github.io/medical-ai-course-materials/notebooks/01_Basic_Math_for_ML.html#:~:text=%5C%5B%5Cbegin,split))。先の例では勾配は $(3,\ 4)$ というベクトルになります。

勾配は関数の各方向（各変数）に沿った傾きをまとめたものです。幾何学的には、勾配ベクトルは現在地において関数値を**最も速く増加させる方向**を指します ([アルゴリズムとは？ 意味や使い方、具体例をわかりやすく解説｜SmartCompany（スマカン）](https://smartcompany.jp/column/algorithm/#:~:text=match%20at%20L213%20%E6%9C%80%E9%81%A9%E5%8C%96%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0%E3%81%A8%E3%81%AF%E3%80%81%E6%9C%80%E5%B0%8F%E5%80%A4%E3%82%84%E6%9C%80%E5%A4%A7%E5%80%A4%E3%82%92%E6%B1%82%E3%82%81%E3%82%8B%E5%95%8F%E9%A1%8C%E3%81%A7%E5%8A%B9%E7%8E%87%E7%9A%84%E3%81%AB%E8%A7%A3%E7%AD%94%E3%82%92%E5%B0%8E%E3%81%8F%E3%81%9F%E3%82%81%E3%81%AB%E4%BD%BF%E3%82%8F%E3%82%8C%E3%82%8B%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0%E3%81%A7%E3%81%99%E3%80%82%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%82%92%E5%A7%8B%E3%82%81%E3%81%A8%E3%81%97%E3%81%9F%E5%B9%85%E5%BA%83%E3%81%84%E5%88%86%E9%87%8E%E3%81%A7%E4%BD%BF%E3%82%8F%E3%82%8C%E3%81%A6%E3%81%84%E3%81%BE%E3%81%99%E3%80%82))。逆にマイナス勾配は最も減少する方向です。この性質を利用して後述の最適化手法（勾配降下法）では勾配の反対方向にパラメータを更新していきます。いずれにせよ、微分や偏微分の計算が機械学習アルゴリズム理解の土台になります。

**Pythonで微分を計算してみる:** Pythonにはシンボリック計算を行う`sympy`ライブラリがあり、微分も自動計算できます。例えば先ほどの$f(x)=(3x+4)^2$を微分させてみましょう。

```python
from sympy import symbols, diff
x = symbols('x')
f = (3*x + 4)**2
print(diff(f, x))
```

このコードを実行すると、`6*(3*x + 4)` という結果が得られます。手計算した結果$f'(x)=6(3x+4)$と一致していることが確認できます。このように、プログラミングを使って微分計算を検証したり自動化することも可能です。

### 線形代数の基礎

**線形代数**はベクトルや行列などを扱う数学分野で、機械学習ではデータやモデルのパラメータを行列で表現するため必須の知識です ([1. 機械学習に必要な数学の基礎 — メディカルAI専門コース オンライン講義資料  documentation](https://japan-medical-ai.github.io/medical-ai-course-materials/notebooks/01_Basic_Math_for_ML.html#:~:text=1))。まず基本となる**スカラー・ベクトル・行列・テンソル**について押さえましょう ([1. 機械学習に必要な数学の基礎 — メディカルAI専門コース オンライン講義資料  documentation](https://japan-medical-ai.github.io/medical-ai-course-materials/notebooks/01_Basic_Math_for_ML.html#:~:text=1))。

- **スカラー**: 単一の数値（または変数）を指します ([1. 機械学習に必要な数学の基礎 — メディカルAI専門コース オンライン講義資料  documentation](https://japan-medical-ai.github.io/medical-ai-course-materials/notebooks/01_Basic_Math_for_ML.html#:~:text=%E3%82%B9%E3%82%AB%E3%83%A9%E3%83%BC%20%E3%81%AF%EF%BC%8C1%E3%81%A4%E3%81%AE%E5%80%A4%E3%82%82%E3%81%97%E3%81%8F%E3%81%AF%E5%A4%89%E6%95%B0%E3%81%AE%E3%81%93%E3%81%A8%E3%81%A7%E3%81%99%EF%BC%8E%E4%BE%8B%E3%81%88%E3%81%B0%EF%BC%8C))。例えば $x=3$ や $y$ など一つの値はスカラーです。スカラーは温度や身長など**1次元の量**の表現に対応します。

- **ベクトル**: 複数のスカラーを一列に並べたものです ([1. 機械学習に必要な数学の基礎 — メディカルAI専門コース オンライン講義資料  documentation](https://japan-medical-ai.github.io/medical-ai-course-materials/notebooks/01_Basic_Math_for_ML.html#:~:text=%E3%83%99%E3%82%AF%E3%83%88%E3%83%AB%20%E3%81%AF%EF%BC%8C%E8%A4%87%E6%95%B0%E3%81%AE%E3%82%B9%E3%82%AB%E3%83%A9%E3%83%BC%E3%82%92%E7%B8%A6%E6%96%B9%E5%90%91%EF%BC%88%E3%82%82%E3%81%97%E3%81%8F%E3%81%AF%E6%A8%AA%E6%96%B9%E5%90%91%EF%BC%89%E3%81%AB%E9%9B%86%E3%82%81%E3%81%A6%E4%B8%A6%E3%81%B9%E3%81%9F%E3%82%82%E3%81%AE%E3%81%A7%E3%81%82%E3%82%8A%EF%BC%8C))。例えば $\mathbf{v} = \begin{bmatrix}v_1 \\ v_2 \\ v_3\end{bmatrix}$ のように縦方向に成分を並べた列（コラム）ベクトルで表します（横に並べた行ベクトルとして表すこともありますが、機械学習では列ベクトルを指すことが多いです ([1. 機械学習に必要な数学の基礎 — メディカルAI専門コース オンライン講義資料  documentation](https://japan-medical-ai.github.io/medical-ai-course-materials/notebooks/01_Basic_Math_for_ML.html#:~:text=match%20at%20L247%20%E3%81%AE%E3%82%88%E3%81%86%E3%81%AB%E8%A1%A8%E3%81%97%E3%81%BE%E3%81%99%EF%BC%8E%E3%83%99%E3%82%AF%E3%83%88%E3%83%AB%E3%81%AE%E8%A1%A8%E8%A8%98%E3%81%AF%E5%A4%AA%E6%96%87%E5%AD%97%E3%81%A8%E3%81%99%E3%82%8B%E5%A0%B4%E5%90%88%E3%81%8C%E5%A4%9A%E3%81%8F%EF%BC%8C%E3%82%B9%E3%82%AB%E3%83%A9%E3%83%BC%E3%81%8B%E3%83%99%E3%82%AF%E3%83%88%E3%83%AB%E3%81%8B%E3%82%92%E5%8C%BA%E5%88%A5%E3%81%A7%E3%81%8D%E3%82%8B%E3%82%88%E3%81%86%E3%81%AB%E3%81%97%E3%81%A6%E3%81%84%E3%81%BE%E3%81%99%EF%BC%8E%E3%83%99%E3%82%AF%E3%83%88%E3%83%AB%E3%82%92%E8%A1%A8%E7%8F%BE%E3%81%99%E3%82%8B%E9%9A%9B%EF%BC%8C%E7%B8%A6%E6%96%B9%E5%90%91%E3%81%AB%E4%B8%A6%E3%81%B9%E3%81%9F%E3%82%82%E3%81%AE%E3%82%92%E5%88%97%E3%83%99%E3%82%AF%E3%83%88%E3%83%AB%20%EF%BC%8C%E6%A8%AA%E6%96%B9%E5%90%91%E3%81%AB%E4%B8%A6%E3%81%B9%E3%81%9F%E3%82%82%E3%81%AE%E3%82%92%E8%A1%8C%E3%83%99%E3%82%AF%E3%83%88%E3%83%AB%E3%81%A8%E3%82%88%E3%81%B3%E3%81%BE%E3%81%99%EF%BC%8E%E6%95%B0%E5%AD%A6%E3%82%84%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%81%A7%E3%81%AF%E5%88%97%E3%83%99%E3%82%AF%E3%83%88%E3%83%AB%E3%82%92%E5%88%A9%E7%94%A8%E3%81%99%E3%82%8B%E8%AB%96%E6%96%87%E3%82%84%E5%8F%82%E8%80%83%E6%9B%B8%E3%81%8C%E5%A4%9A%E3%81%84%E3%81%9F%E3%82%81%EF%BC%8C%E7%89%B9%E3%81%AB%E6%98%8E%E7%A4%BA%E3%81%97%E3%81%AA%E3%81%84%E9%99%90%E3%82%8A%EF%BC%8C%E5%8D%98%E3%81%AB%E3%83%99%E3%82%AF%E3%83%88%E3%83%AB%E3%81%A8%E8%A1%A8%E7%8F%BE%E3%81%97%E3%81%9F%E5%A0%B4%E5%90%88%E3%81%AB%E3%81%AF%E5%88%97%E3%83%99,%E3%82%AF%E3%83%88%E3%83%AB%E3%82%92%E6%8C%87%E3%81%99%E3%81%93%E3%81%A8%E3%81%A8%E3%81%97%E3%81%BE%E3%81%99%EF%BC%8E))）。ベクトルは速度のように「大きさと方向」を持つ量や、データの特徴量の集合（特徴ベクトル）を表現します。

- **行列**: 縦方向に$m$行、横方向に$n$列のスカラーを並べた矩形配列を**$m \times n$行列**と言います。行列は例えば $3\times 2$ 行列 $\mathbf{A}=\begin{bmatrix}a_{11} & a_{12} \\ a_{21} & a_{22} \\ a_{31} & a_{32}\end{bmatrix}$ のように表記します。行列はベクトルを行や列に複数並べたものとも見なせ、**2次元（2階）のテンソル**とも言えます ([1. 機械学習に必要な数学の基礎 — メディカルAI専門コース オンライン講義資料  documentation](https://japan-medical-ai.github.io/medical-ai-course-materials/notebooks/01_Basic_Math_for_ML.html#:~:text=2))。行列はデータセット（行列の各行にサンプルを並べる）や、線形変換（後述）を表すのに用いられます。行列は通常、大文字（ボールド体の場合もあり）で表記します ([1. 機械学習に必要な数学の基礎 — メディカルAI専門コース オンライン講義資料  documentation](https://japan-medical-ai.github.io/medical-ai-course-materials/notebooks/01_Basic_Math_for_ML.html#:~:text=2))。

- **テンソル**: テンソルはベクトルや行列をさらに高次元に拡張した概念です ([1. 機械学習に必要な数学の基礎 — メディカルAI専門コース オンライン講義資料  documentation](https://japan-medical-ai.github.io/medical-ai-course-materials/notebooks/01_Basic_Math_for_ML.html#:~:text=2))。1階のテンソルがベクトル、2階が行列、3階以上になると高次元配列（例えば色画像は高さ×幅×色チャネルの3次元テンソル）となります ([1. 機械学習に必要な数学の基礎 — メディカルAI専門コース オンライン講義資料  documentation](https://japan-medical-ai.github.io/medical-ai-course-materials/notebooks/01_Basic_Math_for_ML.html#:~:text=2))。深層学習では多次元のテンソルを直接操作することが多く、ライブラリ（NumPyやPyTorchなど）でもテンソルの形でデータを扱います。

**線形代数の基本演算:** ベクトル・行列には様々な演算がありますが、以下の基本を押さえておきましょう。

- **ベクトルの加減算:** 同じ次元のベクトル同士は、それぞれの成分を足し合わせて新たなベクトルを得ます（減算も同様）。例えば $\mathbf{u}=\begin{bmatrix}1\\2\end{bmatrix}, \mathbf{v}=\begin{bmatrix}3\\-1\end{bmatrix}$ のとき、$\mathbf{u}+\mathbf{v}=\begin{bmatrix}4\\1\end{bmatrix}$ となります。行列同士の加減算も、同じサイズ同士で成分ごとに計算します。

- **スカラー倍:** ベクトル（や行列）にスカラー$\alpha$を掛けると、全ての成分が$\alpha$倍されます。例えば $2 \cdot \begin{bmatrix}3\\4\end{bmatrix} = \begin{bmatrix}6\\8\end{bmatrix}$ です。

- **内積（ドット積）:** ベクトル同士の積の一種で、同じ次元のベクトル間の内積は対応する成分同士を掛けて足し合わせたスカラーになります ([1. 機械学習に必要な数学の基礎 — メディカルAI専門コース オンライン講義資料  documentation](https://japan-medical-ai.github.io/medical-ai-course-materials/notebooks/01_Basic_Math_for_ML.html#:~:text=%E5%B0%8F%E6%96%87%E5%AD%97%20%E5%A4%A7%E6%96%87%E5%AD%97%20%E7%B4%B0%E6%96%87%E5%AD%97%20%E3%82%B9%E3%82%AB%E3%83%A9%E3%83%BC%E3%81%AE%E5%A4%89%E6%95%B0%20%E3%82%B9%E3%82%AB%E3%83%A9%E3%83%BC%E3%81%AE%E5%AE%9A%E6%95%B0))。例：$\mathbf{u}\cdot \mathbf{v} = u_1v_1 + u_2v_2 + \dots + u_n v_n$。内積は2つのベクトルの類似度（なす角）を測るのに使われ、機械学習では重み付き和や相関の計算で頻出します。特に**ユークリッドノルム**（ベクトルの長さ）は$\|\mathbf{v}\|=\sqrt{\mathbf{v}\cdot \mathbf{v}}$で定義されます。

- **行列とベクトルの積:** $m\times n$行列$\mathbf{A}$と$n$次元ベクトル$\mathbf{x}$の積$\mathbf{A}\mathbf{x}$は、結果が$m$次元のベクトルになります。計算方法は、$\mathbf{A}$の各行とベクトル$\mathbf{x}$の内積を成分として並べる形です。例えば $\mathbf{A}=\begin{bmatrix}a&b\\c&d\\e&f\end{bmatrix}, \mathbf{x}=\begin{bmatrix}x\\y\end{bmatrix}$ のとき、$\mathbf{A}\mathbf{x}=\begin{bmatrix}ax+by\\ cx+dy\\ ex+fy\end{bmatrix}$ となります。行列-ベクトル積は**線形変換**を表現します。機械学習では、モデルの重みを行列$W$、入力特徴をベクトル$\mathbf{x}$で表し、$W\mathbf{x}$が出力の線形項になる、という具合に活用されます。

- **行列と行列の積:** 行列同士も積が定義されます。$A$（サイズ$p\times q$）と$B$（サイズ$q\times r$）が掛けられる条件は、$A$の列数$q$と$B$の行数$q$が等しいことです。積$C = AB$はサイズ$p\times r$の行列で、$C$の各要素は$C_{ij} = \sum_{k=1}^{q} A_{ik} B_{kj}$という計算で得られます。行列積は一般に**可換ではない**（$AB \neq BA$となる場合が多い）点に注意が必要です ([1. 機械学習に必要な数学の基礎 — メディカルAI専門コース オンライン講義資料  documentation](https://japan-medical-ai.github.io/medical-ai-course-materials/notebooks/01_Basic_Math_for_ML.html#:~:text=%E5%B0%8F%E6%96%87%E5%AD%97%20%E5%A4%A7%E6%96%87%E5%AD%97%20%E7%B4%B0%E6%96%87%E5%AD%97%20%E3%82%B9%E3%82%AB%E3%83%A9%E3%83%BC%E3%81%AE%E5%A4%89%E6%95%B0%20%E3%82%B9%E3%82%AB%E3%83%A9%E3%83%BC%E3%81%AE%E5%AE%9A%E6%95%B0))。行列積は繰り返し線形変換を適用することに相当し、例えば多層のニューラルネットワークでは各層の重み行列を順に掛け合わせる形で入力から出力への写像を表現します。

- **転置:** 行列の行と列を入れ替える操作を**転置**といいます。$A$の転置は$A^T$と表し、サイズが元の$ n\times m $から $ m\times n $になります。例えば $A=\begin{bmatrix}1 & 2 & 3\\ 4 & 5 & 6\end{bmatrix}$ に対し $A^T=\begin{bmatrix}1 & 4\\ 2 & 5\\ 3 & 6\end{bmatrix}$ です。ベクトルは縦横の区別があるので、列ベクトル$\mathbf{x}$を横にしたものは$\mathbf{x}^T$と書きます。

- **単位行列と逆行列:** **単位行列**$I$は対角成分が全て1、その他が0の正方行列です ([1. 機械学習に必要な数学の基礎 — メディカルAI専門コース オンライン講義資料  documentation](https://japan-medical-ai.github.io/medical-ai-course-materials/notebooks/01_Basic_Math_for_ML.html#:~:text=%E3%81%A8%E3%82%88%E3%81%B3%EF%BC%8C%E3%81%9D%E3%82%8C%E4%BB%A5%E5%A4%96%E3%81%AE%E8%A6%81%E7%B4%A0%E3%82%92%E9%9D%9E%E5%AF%BE%E8%A7%92%E8%A6%81%E7%B4%A0%E3%81%A8%E3%82%88%E3%81%B3%E3%81%BE%E3%81%99%EF%BC%8E%E5%8D%98%E4%BD%8D%E8%A1%8C%E5%88%97%E3%81%AF%EF%BC%8C%E5%AF%BE%E8%A7%92%E8%A6%81%E7%B4%A0%E3%81%8C1%E3%81%A7%EF%BC%8C%E9%9D%9E%E5%AF%BE%E8%A7%92%E8%A6%81%E7%B4%A0%E3%81%8C0%E3%81%A7%E3%81%82%E3%82%8B%E3%82%88%E3%81%86%E3%81%AA%20%E6%AD%A3%E6%96%B9%E8%A1%8C%E5%88%97%EF%BC%88%E8%A1%8C%E8%A6%81%E7%B4%A0%E3%81%AE%E6%95%B0%E3%81%A8%E5%88%97%E8%A6%81%E7%B4%A0%E3%81%AE%E6%95%B0%E3%81%8C%E4%B8%80%E8%87%B4%E3%81%99%E3%82%8B%E8%A1%8C%E5%88%97%EF%BC%89%E3%81%A7%E3%81%99%EF%BC%8E%E4%BE%8B%E3%81%88%E3%81%B0%EF%BC%8C%20))。$2\times2$の単位行列は $\begin{bmatrix}1&0\\0&1\end{bmatrix}$、$3\times3$なら$\begin{bmatrix}1&0&0\\0&1&0\\0&0&1\end{bmatrix}$ です。単位行列は行列の掛け算における1の役割を果たし、任意の正方行列$A$について $AI = IA = A$ となります ([1. 機械学習に必要な数学の基礎 — メディカルAI専門コース オンライン講義資料  documentation](https://japan-medical-ai.github.io/medical-ai-course-materials/notebooks/01_Basic_Math_for_ML.html#:~:text=%E5%8D%98%E4%BD%8D%E8%A1%8C%E5%88%97%E3%81%AF%E4%BB%BB%E6%84%8F%E3%81%AE%E6%AD%A3%E6%96%B9%E8%A1%8C%E5%88%97%5C%28%5Cbf))。**逆行列**とは、ある正方行列$A$に対して $A^{-1}$ を掛けると単位行列になる行列のことです ([1. 機械学習に必要な数学の基礎 — メディカルAI専門コース オンライン講義資料  documentation](https://japan-medical-ai.github.io/medical-ai-course-materials/notebooks/01_Basic_Math_for_ML.html#:~:text=1%5C%29%29%E3%81%AB%E5%AF%BE%E5%BF%9C%E3%81%99%E3%82%8B%E3%82%88%E3%81%86%E3%81%AA%E8%A1%8C%E5%88%97%E3%81%A7%E3%81%99%EF%BC%8E%E8%A1%8C%E5%88%97%5C%28%5Cbf%7BA%7D%5C%29%E3%81%AB%E5%AF%BE%E3%81%97%EF%BC%8C%E3%81%9D%E3%81%AE%E9%80%86%E8%A1%8C%E5%88%97%E3%81%AF%5C%28%5Cbf%7BA%7D%5E%7B))。すなわち $A A^{-1} = A^{-1} A = I$ を満たします。逆行列はスカラーの逆数に相当し、例えば $2\times2$行列 $A=\begin{bmatrix}a&b\\c&d\end{bmatrix}$ の逆行列は $A^{-1}=\frac{1}{ad-bc}\begin{bmatrix}d&-b\\-c&a\end{bmatrix}$（ただし$ad-bc \neq 0$）で与えられます。$ad-bc=0$の場合は逆行列が存在せず、その行列は**正則でない（特異）**と言います ([1. 機械学習に必要な数学の基礎 — メディカルAI専門コース オンライン講義資料  documentation](https://japan-medical-ai.github.io/medical-ai-course-materials/notebooks/01_Basic_Math_for_ML.html#:~:text=match%20at%20L428%20%E9%80%86%E8%A1%8C%E5%88%97%E3%81%AF%E5%B8%B8%E3%81%AB%E5%AD%98%E5%9C%A8%E3%81%99%E3%82%8B%E3%81%A8%E3%81%AF%E9%99%90%E3%82%8A%E3%81%BE%E3%81%9B%E3%82%93%EF%BC%8E%E9%80%86%E8%A1%8C%E5%88%97%E3%81%8C%E5%AD%98%E5%9C%A8%E3%81%99%E3%82%8B%E3%82%88%E3%81%86%E3%81%AA%E8%A1%8C%E5%88%97%E3%81%AE%E3%81%93%E3%81%A8%E3%82%92%20%E6%AD%A3%E5%89%87%E8%A1%8C%E5%88%97,%E3%81%A8%E3%82%88%E3%81%B3%E3%81%BE%E3%81%99%EF%BC%88%E8%A1%8C%E5%88%97%E3%81%8C%E6%AD%A3%E5%89%87%E3%81%A7%E3%81%82%E3%82%8B%E3%81%9F%E3%82%81%E3%81%AE%E6%9D%A1%E4%BB%B6%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6%E3%81%AF%E4%BB%8A%E5%9B%9E%E3%81%AF%E8%AA%AC%E6%98%8E%E3%81%97%E3%81%BE%E3%81%9B%E3%82%93%EF%BC%89%EF%BC%8E))。機械学習では、モデルの解析解（例えば正規方程式による線形回帰の解）を求める際に逆行列を使うことがあります。ただし行列サイズが大きい場合は数値的に直接逆行列を計算するのは非効率なため、実装上は解法に工夫をします。

**Pythonで行列演算:** PythonのNumPyライブラリを使うとベクトルや行列を手軽に扱えます。例として行列積を計算してみます。

```python
import numpy as np

A = np.array([[1, 2], 
              [3, 4]])
B = np.array([[2, 0], 
              [1, 3]])

print("A =\n", A)
print("B =\n", B)
print("A * B =\n", A.dot(B))
```

出力:
```
A =
 [[1 2]
  [3 4]]
B =
 [[2 0]
  [1 3]]
A * B =
 [[4 6]
  [10 12]]
```

ここでは $A = \begin{bmatrix}1 & 2\\ 3 & 4\end{bmatrix}$、$B = \begin{bmatrix}2 & 0\\ 1 & 3\end{bmatrix}$ とし、`A.dot(B)`で行列積を計算しています。結果は $\begin{bmatrix}4 & 6\\ 10 & 12\end{bmatrix}$ となり、筆算した $AB = \begin{bmatrix}1*2 + 2*1 & 1*0 + 2*3\\ 3*2 + 4*1 & 3*0 + 4*3\end{bmatrix} = \begin{bmatrix}4 & 6\\ 10 & 12\end{bmatrix}$ と一致しています。

このように、NumPyを使えばベクトルや行列の演算を簡潔に書けます。線形代数の知識と併せて、実際のコード上での扱い方も覚えておくと良いでしょう。

### 確率・統計の基礎

機械学習ではデータのばらつきや不確実性を扱うために**確率・統計**の知識も重要です ([機械学習に数学の知識は必要？最低限の基礎知識を徹底解説 - doda](https://doda.jp/engineer/guide/it/052.html#:~:text=%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%81%AB%E6%95%B0%E5%AD%A6%E3%81%AE%E7%9F%A5%E8%AD%98%E3%81%AF%E5%BF%85%E8%A6%81%EF%BC%9F%E6%9C%80%E4%BD%8E%E9%99%90%E3%81%AE%E5%9F%BA%E7%A4%8E%E7%9F%A5%E8%AD%98%E3%82%92%E5%BE%B9%E5%BA%95%E8%A7%A3%E8%AA%AC%20)) ([機械学習に数学の知識は必要？最低限の基礎知識を徹底解説 - doda](https://doda.jp/engineer/guide/it/052.html#:~:text=%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%81%AE%E6%95%B0%E5%AD%A6%E3%81%A7%E3%81%AF%E3%80%81%E5%89%8D%E8%BF%B0%E3%81%AE%E3%82%88%E3%81%86%E3%81%AB%E5%BE%AE%E5%88%86%E3%81%A8%E7%B7%9A%E5%BD%A2%E4%BB%A3%E6%95%B0%EF%BC%88%E8%A1%8C%E5%88%97%EF%BC%89%E3%82%92%E3%83%9E%E3%82%B9%E3%82%BF%E3%83%BC%E3%81%97%E3%81%A6%E3%81%84%E3%82%8C%E3%81%B0%E3%80%81%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0%E3%82%92%E7%90%86%E8%A7%A3%E3%81%99%E3%82%8B%E3%81%93%E3%81%A8%E3%81%8C%E3%81%A7%E3%81%8D%E3%81%BE%E3%81%99%E3%80%82%E3%81%A7%E3%81%AF%E3%80%81%E3%81%AA%E3%81%9C%E7%A2%BA%E7%8E%87%E3%83%BB%E7%B5%B1%E8%A8%88%E3%81%AE%E7%9F%A5%E8%AD%98%20))。ここでは基本的な概念と機械学習との関わりについて説明します。

**確率と確率分布:** 確率とは、ある事象が起こる可能性を0～1の範囲の値で表したものです。例えばコイン投げで表が出る確率は0.5（50%）です。確率論では、すべての結果とその確率を記述した**確率分布**を考えます。連続的な値を取る場合は確率密度として表し、例えば**正規分布（ガウス分布）**は平均$\mu$、分散$\sigma^2$を持つ連続分布で、その確率密度関数は次のようになります ([1. 機械学習に必要な数学の基礎 — メディカルAI専門コース オンライン講義資料  documentation](https://japan-medical-ai.github.io/medical-ai-course-materials/notebooks/01_Basic_Math_for_ML.html#:~:text=,27)):

\[ f(x) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\!\Big(-\frac{(x-\mu)^2}{2\sigma^2}\Big) \,. \]

正規分布は自然界や誤差の分布を表す基本的なモデルで、機械学習でもデータのノイズを正規分布と仮定することがよくあります。また、正規分布に従うデータでは平均$\mu$±$2\sigma$の範囲に約95%のデータが収まるなどの性質があり、外れ値検出や特徴量のスケーリング（標準化）に利用されます ([1. 機械学習に必要な数学の基礎 — メディカルAI専門コース オンライン講義資料  documentation](https://japan-medical-ai.github.io/medical-ai-course-materials/notebooks/01_Basic_Math_for_ML.html#:~:text=,27)) ([1. 機械学習に必要な数学の基礎 — メディカルAI専門コース オンライン講義資料  documentation](https://japan-medical-ai.github.io/medical-ai-course-materials/notebooks/01_Basic_Math_for_ML.html#:~:text=,23))。

**統計量（平均・分散など）:** データ集合の特徴を数値で表す量を**統計量**と呼びます。一番基本的なのは**平均値**と**分散**です。データ$x_1,\dots,x_N$の平均は $\displaystyle \bar{x}=\frac{1}{N}\sum_{i=1}^{N}x_i$、分散は $\displaystyle \mathrm{Var}(x)=\frac{1}{N}\sum_{i=1}^{N}(x_i-\bar{x})^2$ で定義されます。分散の正の平方根を**標準偏差**と呼びます。平均はデータの「中心」、分散・標準偏差は「ばらつき」の尺度です。機械学習では特徴量ごとの値のスケールが大きく異なると学習がうまくいかないことがありますが、各特徴量を平均0・標準偏差1に揃える**標準化（Zスコア変換）**を行うことで改善できます ([1. 機械学習に必要な数学の基礎 — メディカルAI専門コース オンライン講義資料  documentation](https://japan-medical-ai.github.io/medical-ai-course-materials/notebooks/01_Basic_Math_for_ML.html#:~:text=,29))。これは各値から平均を引いて標準偏差で割る操作です。そうすることで全ての特徴が平均0・分散1になり、学習アルゴリズムが各特徴を均等に扱いやすくなります ([1. 機械学習に必要な数学の基礎 — メディカルAI専門コース オンライン講義資料  documentation](https://japan-medical-ai.github.io/medical-ai-course-materials/notebooks/01_Basic_Math_for_ML.html#:~:text=,27)) ([1. 機械学習に必要な数学の基礎 — メディカルAI専門コース オンライン講義資料  documentation](https://japan-medical-ai.github.io/medical-ai-course-materials/notebooks/01_Basic_Math_for_ML.html#:~:text=,23))。

**確率と機械学習:** 機械学習では、モデルの予測やデータの生成プロセスを確率的に捉えることがあります。例えば「ある入力$x$に対してクラス$y$である確率」は $P(y|x)$ と表されます。分類モデルの訓練では、各訓練データ$(x_i, y_i)$についてモデルがその$y_i$を予測する確率を高めるようパラメータを調整します。このとき**対数尤度**や**交差エントロピー**といった確率に基づく損失関数が用いられます。これは統計の**最尤推定法**に対応しており、モデルが与えられたデータを最もよく説明する（データの生起確率を最大化する）ようにパラメータを求める考え方です ([1. 機械学習に必要な数学の基礎 — メディカルAI専門コース オンライン講義資料  documentation](https://japan-medical-ai.github.io/medical-ai-course-materials/notebooks/01_Basic_Math_for_ML.html#:~:text=,23))。

例えばロジスティック回帰は、クラス1である確率を $\sigma(w\cdot x)$（シグモイド関数適用後の値）でモデル化し、その尤度を最大化するよう$w$を学習します。これは実質的に**交差エントロピー損失**を最小化することと同じであり、確率的解釈の下で損失関数が導かれている例です。

**統計的仮定と検定:** モデル評価においても統計の知識が役立ちます。例えば「このモデルの精度向上は偶然ではないと言えるか？」を判断するには統計的仮説検定の考え方を用います。また、汎化性能評価では偶然の分割によるブレを抑えるためにクロスバリデーションを行うなど、統計学的な手法が取り入れられています。

### まとめ

第2章では、機械学習を支える数学として微分・線形代数・確率統計の基礎を学びました。微分では関数の変化率を求め、学習における最適化計算（勾配降下法など）に不可欠です。線形代数ではベクトルや行列によるデータ表現と演算を学び、重みや特徴量の操作を理解する素地を築きました。確率統計ではデータの不確実性や分布の概念を学び、モデルの評価や損失関数の設計などに統計的視点が活かされることを見ました。この章の内容は機械学習アルゴリズムの数理を理解する土台となります。

## 第3章：機械学習の基本

それでは、いよいよ**機械学習（Machine Learning）**の基本について学びましょう。機械学習とは「データから経験的に学習し、将来の予測や判断を行うこと」です ([機械学習とは？仕組み、手法、学び方から利用例まで - MathWorks](https://jp.mathworks.com/discovery/machine-learning.html#:~:text=%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%81%A8%E3%81%AF%EF%BC%9F%E4%BB%95%E7%B5%84%E3%81%BF%E3%80%81%E6%89%8B%E6%B3%95%E3%80%81%E5%AD%A6%E3%81%B3%E6%96%B9%E3%81%8B%E3%82%89%E5%88%A9%E7%94%A8%E4%BE%8B%E3%81%BE%E3%81%A7%20))。伝統的なプログラミングとの最大の違いは、**プログラム（ルール）そのものを人間が書くのではなく、コンピュータがデータから自動的に獲得する**点にあります。従来型のプログラミングでは**入力**と**アルゴリズム（プログラム）**を与えて**出力**を得ますが、機械学習では**入力**と**出力（正解）**を与えてコンピュータに学習させ、**アルゴリズム（モデル）**を獲得させます ([〖机器学习〗一些基本概念及符号系统 - 昕-2008 - 博客园](https://www.cnblogs.com/Belter/p/6323390.html#:~:text=%E5%A6%82%E6%9E%9C%E5%B0%86%E4%B8%80%E4%B8%AA%E7%A8%8B%E5%BA%8F%E5%A4%A7%E8%87%B4%E5%88%86%E4%B8%BA%E4%B8%89%E4%B8%AA%E9%83%A8%E5%88%86%EF%BC%9A%E8%BE%93%E5%85%A5%E3%80%81%E8%BE%93%E5%87%BA%E5%92%8C%E7%AE%97%E6%B3%95%EF%BC%8C%E9%82%A3%E4%B9%88%E4%BC%A0%E7%BB%9F%E7%BC%96%E7%A8%8B%E4%B8%AD%E5%B7%B2%E7%9F%A5%E7%9A%84%E6%98%AF%E8%BE%93%E5%85%A5%E5%92%8C%E7%AE%97%E6%B3%95%EF%BC%8C%E9%9C%80%E8%A6%81%E6%B1%82%E8%BE%93%E5%87%BA%EF%BC%9B%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%88%99%E6%98%AF%E5%B7%B2%E7%9F%A5%E8%BE%93%E5%85%A5%E5%92%8C%E8%BE%93%E5%87%BA%EF%BC%8C%E9%9C%80%E8%A6%81%E9%80%9A%E8%BF%87%E8%AE%AD%E7%BB%83%EF%BC%88%E5%AD%A6%E4%B9%A0%EF%BC%89%E6%9D%A5%E5%BE%97%E5%88%B0%E6%9C%89%E6%B3%9B%E5%8C%96%E8%83%BD%20%E5%8A%9B%E7%9A%84%E7%AE%97%E6%B3%95%E3%80%82))。この発想の転換により、明確なプログラム記述が難しい複雑な問題（画像認識や音声認識など）にもコンピュータが対応できるようになりました。

まず、機械学習の位置づけを整理します。**人工知能 (AI)**という広い概念の中に**機械学習**が含まれ、さらにその一手法として**深層学習 (ディープラーニング)**があります ([世界一わかりやすい機械学習プログラミングチュートリアル #Python - Qiita](https://qiita.com/nuco_fn/items/75272b5f4a3c27da132a#:~:text=%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%82%92%E5%A7%8B%E3%82%81%E3%82%88%E3%81%86%E3%81%A8%E3%81%99%E3%82%8B%E3%81%A8AI%E3%80%81%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%80%81%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0%E3%81%A8%E3%81%84%E3%81%86%E3%83%AF%E3%83%BC%E3%83%89%E3%82%92%E7%9B%AE%E3%81%AB%E3%81%99%E3%82%8B%E3%81%A8%E6%80%9D%E3%81%84%E3%81%BE%E3%81%99%E3%80%82%E3%81%BE%E3%81%9A%E3%80%81%E6%B7%B7%E5%90%88%E3%81%97%E3%81%8C%E3%81%A1%E3%81%AA%E3%81%93%E3%82%8C%E3%82%89%E3%81%AE%E9%81%95%E3%81%84%E3%81%8B%E3%82%89%E8%AA%AC%E6%98%8E%E3%81%99%E3%82%8B%E3%81%A8%E3%80%81AI))。深層学習は多層のニューラルネットワークを用いる機械学習アルゴリズムの一種で、第4章以降で詳しく学ぶTransformersもこの深層学習の発展形です。本章ではまず、深層学習を含めた機械学習全般に共通する基本概念を押さえます。

### 機械学習の種類

機械学習の手法は学習データの与え方によって大きく3種類に分類されます ([機械学習とは？種類やできること、プログラムとの違いを解説 ｜転職ならdodaエンジニア IT](https://doda.jp/engineer/guide/it/048.html#:~:text=%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%81%AE%E7%A8%AE%E9%A1%9E))。

- **教師あり学習 (Supervised Learning):** 入力データとそれに対応する正解ラベル（目的変数）がペアで与えられたデータ（訓練データ）を使って学習します ([機械学習とは？種類やできること、プログラムとの違いを解説 ｜転職ならdodaエンジニア IT](https://doda.jp/engineer/guide/it/048.html#:~:text=%E6%95%99%E5%B8%AB%E3%81%82%E3%82%8A%E5%AD%A6%E7%BF%92))。モデルは与えられた例から「入力から出力への対応関係」を学習し、新しい入力に対して正解を予測できるようになります。典型的なタスクは**分類**（例: 画像から犬か猫かを判別）や**回帰**（例: 間取りや築年数から家賃価格を予測）です。教師あり学習では正解が明示されているため、モデルの良し悪しを測る指標（正答率や誤差など）もはっきりしています。

- **教師なし学習 (Unsupervised Learning):** データに正解ラベルがない状態で学習します ([機械学習とは？種類やできること、プログラムとの違いを解説 ｜転職ならdodaエンジニア IT](https://doda.jp/engineer/guide/it/048.html#:~:text=%E6%95%99%E5%B8%AB%E3%81%AA%E3%81%97%E5%AD%A6%E7%BF%92))。モデルはデータの構造を自律的に発見しようとします。典型的なタスクは**クラスタリング**（データを似たもの同士のグループに分ける）や**次元圧縮**（高次元のデータを情報をなるべく失わずに低次元に表現する、例: 主成分分析）です ([機械学習とは？種類やできること、プログラムとの違いを解説 ｜転職ならdodaエンジニア IT](https://doda.jp/engineer/guide/it/048.html#:~:text=%E6%95%99%E5%B8%AB%E3%81%AA%E3%81%97%E5%AD%A6%E7%BF%92))。教師なし学習では「正解」がないため評価が難しい側面もありますが、データのパターン発見や特徴抽出に有用です。

- **強化学習 (Reinforcement Learning):** エージェント（学習者）が環境との相互作用を通じて試行錯誤し、報酬を最大化するような行動方策を学習します。ゲームAIやロボット制御などで使われます。強化学習では即時の「正解行動」は与えられず、たまに与えられる報酬を手がかりに長期的に最善となる戦略を学習します。

機械学習というとまず教師あり学習を指すことが多いですが、実際には上記のように様々な形態があります。ここでは**教師あり学習**の流れを中心に、機械学習モデルの学習プロセスを見ていきます。

### 教師あり学習の流れ

教師あり学習では、まず**訓練データ（トレーニングセット）**を用意します。これは入力データとそれに対応する正解ラベルの集合です。モデルはこの訓練データを観察し、入力から出力への一般的な規則を学習します。この過程を図式化すると、**「訓練データ」**を**「学習アルゴリズム」**に与えることで**「モデル（仮説 $h$）」**が生成されるイメージになります。得られたモデル$h$は、新たな入力$x$に対して予測$y$を出力できるようになります（図2）。

 ([〖机器学习〗一些基本概念及符号系统 - 昕-2008 - 博客园](https://www.cnblogs.com/Belter/p/6323390.html))  
*図2: 教師あり学習の基本プロセス。訓練データ（入力と出力のペアの集合）を機械学習アルゴリズムに与えると、入力$\mathbf{X}$から出力$y$を予測するモデル（関数）$h$が学習される。 ([〖机器学习〗一些基本概念及符号系统 - 昕-2008 - 博客园](https://www.cnblogs.com/Belter/p/6323390.html#:~:text=%E5%A6%82%E6%9E%9C%E5%B0%86%E4%B8%80%E4%B8%AA%E7%A8%8B%E5%BA%8F%E5%A4%A7%E8%87%B4%E5%88%86%E4%B8%BA%E4%B8%89%E4%B8%AA%E9%83%A8%E5%88%86%EF%BC%9A%E8%BE%93%E5%85%A5%E3%80%81%E8%BE%93%E5%87%BA%E5%92%8C%E7%AE%97%E6%B3%95%EF%BC%8C%E9%82%A3%E4%B9%88%E4%BC%A0%E7%BB%9F%E7%BC%96%E7%A8%8B%E4%B8%AD%E5%B7%B2%E7%9F%A5%E7%9A%84%E6%98%AF%E8%BE%93%E5%85%A5%E5%92%8C%E7%AE%97%E6%B3%95%EF%BC%8C%E9%9C%80%E8%A6%81%E6%B1%82%E8%BE%93%E5%87%BA%EF%BC%9B%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%88%99%E6%98%AF%E5%B7%B2%E7%9F%A5%E8%BE%93%E5%85%A5%E5%92%8C%E8%BE%93%E5%87%BA%EF%BC%8C%E9%9C%80%E8%A6%81%E9%80%9A%E8%BF%87%E8%AE%AD%E7%BB%83%EF%BC%88%E5%AD%A6%E4%B9%A0%EF%BC%89%E6%9D%A5%E5%BE%97%E5%88%B0%E6%9C%89%E6%B3%9B%E5%8C%96%E8%83%BD%20%E5%8A%9B%E7%9A%84%E7%AE%97%E6%B3%95%E3%80%82))*

学習アルゴリズムとは具体的には、「モデルの構造を定め、そのパラメータをデータに合うよう最適化する手順」です。例えば線形回帰モデルであればモデル構造は「$y = w_0 + w_1 x_1 + \dots + w_M x_M$」という線形方程式で、パラメータは重み$w_0,\dots,w_M$です。学習アルゴリズムではこれら$w$の値を訓練データにフィットするよう調整します。

**損失関数と最適化:** パラメータ調整は通常、**損失関数（コスト関数）**を定義しそれを最小化する問題として定式化されます。損失関数は「モデルの予測の悪さ」を表す指標です。例えば回帰問題では**二乗誤差 (MSE)**、分類問題では**交差エントロピー損失**などが使われます。損失関数$L(\theta)$をモデルの全パラメータ$\theta$の関数とみなし、これを最小にする$\theta$を見つけることが学習の目的になります ([機械学習とは？種類やできること、プログラムとの違いを解説 ｜転職ならdodaエンジニア IT](https://doda.jp/engineer/guide/it/048.html#:~:text=%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%81%AB%E3%81%8A%E3%81%91%E3%82%8B%E6%8E%A8%E8%AB%96%E3%81%AF%E3%80%81%E5%AD%A6%E7%BF%92%E3%81%A8%E3%81%84%E3%81%86%E8%A8%80%E8%91%89%E3%81%8C%E5%85%A5%E3%81%A3%E3%81%A6%E3%81%84%E3%82%8B%E3%82%88%E3%81%86%E3%81%AB%E3%80%81%E6%8E%A8%E8%AB%96%E3%81%AE%E7%B5%90%E6%9E%9C%E3%82%92%E3%81%AA%E3%82%93%E3%82%89%E3%81%8B%E3%81%AE%E6%8C%87%E6%A8%99%E3%81%A7%E8%A9%95%E4%BE%A1%E3%81%97%E3%80%81%E6%8E%A8%E8%AB%96%E3%81%AE%E6%96%B9%E6%B3%95%EF%BC%88%E6%BC%94%E7%AE%97%E5%87%A6%E7%90%86%E3%81%AE%E6%96%B9%E6%B3%95%EF%BC%89%E3%82%92%E6%94%B9%E5%96%84%E3%81%97%E3%81%A6%E3%81%84%E3%81%8D%E3%81%BE%E3%81%99%E3%80%82%E8%A9%95%E4%BE%A1%E5%80%A4%E3%81%AB%E3%82%88%E3%81%A3%E3%81%A6%E6%8E%A8%E8%AB%96%20%E3%81%AE%E7%B2%BE%E5%BA%A6%E3%82%92%E6%94%B9%E5%96%84%E3%81%97%E3%81%A6%E3%81%84%E3%81%8F%E3%81%93%E3%81%A8%E3%82%92%E3%80%8C%E5%AD%A6%E7%BF%92%E3%80%8D%E3%81%A8%E5%91%BC%E3%82%93%E3%81%A7%E3%81%84%E3%81%BE%E3%81%99%E3%80%82))。解析的に解ける場合もありますが、多くの場合は**勾配降下法 (Gradient Descent)**などの数値最適化手法で近似解を求めます ([アルゴリズムとは？ 意味や使い方、具体例をわかりやすく解説｜SmartCompany（スマカン）](https://smartcompany.jp/column/algorithm/#:~:text=%E6%9C%80%E9%81%A9%E5%8C%96%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0%E3%81%A8%E3%81%AF%E3%80%81%E6%9C%80%E5%B0%8F%E5%80%A4%E3%82%84%E6%9C%80%E5%A4%A7%E5%80%A4%E3%82%92%E6%B1%82%E3%82%81%E3%82%8B%E5%95%8F%E9%A1%8C%E3%81%A7%E5%8A%B9%E7%8E%87%E7%9A%84%E3%81%AB%E8%A7%A3%E7%AD%94%E3%82%92%E5%B0%8E%E3%81%8F%E3%81%9F%E3%82%81%E3%81%AB%E4%BD%BF%E3%82%8F%E3%82%8C%E3%82%8B%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0%E3%81%A7%E3%81%99%E3%80%82%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%82%92%E5%A7%8B%E3%82%81%E3%81%A8%E3%81%97%E3%81%9F%E5%B9%85%E5%BA%83%E3%81%84%E5%88%86%E9%87%8E%E3%81%A7%E4%BD%BF%E3%82%8F%E3%82%8C%E3%81%A6%E3%81%84%E3%81%BE%E3%81%99%E3%80%82))。

勾配降下法では、まずパラメータを初期値（ランダムなど）に設定し、損失関数の**勾配（偏微分のベクトル）**を計算して、その**負方向**にパラメータを少しずつ更新していきます ([アルゴリズムとは？ 意味や使い方、具体例をわかりやすく解説｜SmartCompany（スマカン）](https://smartcompany.jp/column/algorithm/#:~:text=match%20at%20L213%20%E6%9C%80%E9%81%A9%E5%8C%96%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0%E3%81%A8%E3%81%AF%E3%80%81%E6%9C%80%E5%B0%8F%E5%80%A4%E3%82%84%E6%9C%80%E5%A4%A7%E5%80%A4%E3%82%92%E6%B1%82%E3%82%81%E3%82%8B%E5%95%8F%E9%A1%8C%E3%81%A7%E5%8A%B9%E7%8E%87%E7%9A%84%E3%81%AB%E8%A7%A3%E7%AD%94%E3%82%92%E5%B0%8E%E3%81%8F%E3%81%9F%E3%82%81%E3%81%AB%E4%BD%BF%E3%82%8F%E3%82%8C%E3%82%8B%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0%E3%81%A7%E3%81%99%E3%80%82%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%82%92%E5%A7%8B%E3%82%81%E3%81%A8%E3%81%97%E3%81%9F%E5%B9%85%E5%BA%83%E3%81%84%E5%88%86%E9%87%8E%E3%81%A7%E4%BD%BF%E3%82%8F%E3%82%8C%E3%81%A6%E3%81%84%E3%81%BE%E3%81%99%E3%80%82))。負の勾配方向は損失を最も減少させる方向なので、学習が進むにつれて損失値は小さくなっていきます。更新ステップは繰り返され、損失がほとんど減らなくなるか一定回数実行された時点でパラメータが確定されます。これがモデルの学習（訓練）完了です。

**例: 線形回帰の学習** – 一次元の線形回帰を例に具体的に見てみます。ある入力$x$から出力$y$を予測するのに $h_w(x) = w_0 + w_1 x$ というモデルを仮定します。訓練データとして2点 $(x_1,y_1),(x_2,y_2)$ が与えられているとしましょう。損失関数に二乗誤差 $L(w_0,w_1) = \frac{1}{2}\big[(w_0+w_1 x_1 - y_1)^2 + (w_0+w_1 x_2 - y_2)^2\big]$ を用い、これを最小にする$w_0,w_1$を求めます。二変数の二次関数なので解析的に最小値を求められますが、勾配降下法でも解いてみます。$w_0$についての偏微分は損失の勾配$\partial L/\partial w_0 = (w_0+w_1 x_1 - y_1) + (w_0+w_1 x_2 - y_2)$、$w_1$については$\partial L/\partial w_1 = (w_0+w_1 x_1 - y_1)x_1 + (w_0+w_1 x_2 - y_2)x_2$となります。これらを使って

\[ w_0 := w_0 - \eta \frac{\partial L}{\partial w_0}, \qquad w_1 := w_1 - \eta \frac{\partial L}{\partial w_1} \]

と学習率$\eta$で重みを更新します。繰り返せばいずれ収束し、最適なパラメータに近づきます。実際、小さなデータセットでは解析解（**正規方程式**による解）も簡単に求められ、線形回帰の場合それは

\[ 
w_1 = \frac{\sum_i (x_i-\bar{x})(y_i-\bar{y})}{\sum_i (x_i-\bar{x})^2}, \qquad
w_0 = \bar{y} - w_1 \bar{x} 
\]

（$\bar{x},\bar{y}$は入力・出力の平均）という公式で与えられます。この結果も、勾配降下法で損失を最小化したものと一致します。

**モデルの評価と過学習:** 学習が一通り完了したら、モデルの性能を評価します。重要なのは**汎化性能**、つまり「訓練に用いていない新しいデータに対する予測精度」です。モデルが訓練データに対して極端に最適化されすぎると、新しいデータへの適応力が落ちる**過学習（オーバーフィッティング）**が起こります ([機械学習とは？種類やできること、プログラムとの違いを解説 ｜転職ならdodaエンジニア IT](https://doda.jp/engineer/guide/it/048.html#:~:text=%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%81%AB%E3%81%8A%E3%81%91%E3%82%8B%E6%8E%A8%E8%AB%96%E3%81%AF%E3%80%81%E5%AD%A6%E7%BF%92%E3%81%A8%E3%81%84%E3%81%86%E8%A8%80%E8%91%89%E3%81%8C%E5%85%A5%E3%81%A3%E3%81%A6%E3%81%84%E3%82%8B%E3%82%88%E3%81%86%E3%81%AB%E3%80%81%E6%8E%A8%E8%AB%96%E3%81%AE%E7%B5%90%E6%9E%9C%E3%82%92%E3%81%AA%E3%82%93%E3%82%89%E3%81%8B%E3%81%AE%E6%8C%87%E6%A8%99%E3%81%A7%E8%A9%95%E4%BE%A1%E3%81%97%E3%80%81%E6%8E%A8%E8%AB%96%E3%81%AE%E6%96%B9%E6%B3%95%EF%BC%88%E6%BC%94%E7%AE%97%E5%87%A6%E7%90%86%E3%81%AE%E6%96%B9%E6%B3%95%EF%BC%89%E3%82%92%E6%94%B9%E5%96%84%E3%81%97%E3%81%A6%E3%81%84%E3%81%8D%E3%81%BE%E3%81%99%E3%80%82%E8%A9%95%E4%BE%A1%E5%80%A4%E3%81%AB%E3%82%88%E3%81%A3%E3%81%A6%E6%8E%A8%E8%AB%96%20%E3%81%AE%E7%B2%BE%E5%BA%A6%E3%82%92%E6%94%B9%E5%96%84%E3%81%97%E3%81%A6%E3%81%84%E3%81%8F%E3%81%93%E3%81%A8%E3%82%92%E3%80%8C%E5%AD%A6%E7%BF%92%E3%80%8D%E3%81%A8%E5%91%BC%E3%82%93%E3%81%A7%E3%81%84%E3%81%BE%E3%81%99%E3%80%82))。過学習を検知するために、手持ちのデータを学習用と評価用に分割します。学習に使わなかった**テストデータ**にモデルを適用し、その予測結果と正解を比べて精度（分類なら正解率、回帰なら平均二乗誤差など）を算出します。このテスト精度がモデルの汎化性能の指標となります。

過学習を防ぐには、**クロスバリデーション**による厳密な評価や**正則化**の導入などが有効です。正則化とは、損失関数にペナルティ項を加えることで過度なパラメータ調整を抑制する手法です（例えば重みの二乗和に比例するペナルティを課すリッジ回帰など）。これによりモデルの複雑さをコントロールし、汎化性能を改善できます。

### 機械学習の適用例とコードによる体験

最後に、簡単な機械学習モデルを実装し動作を確認してみましょう。ここでは**線形回帰**モデルをPythonで学習させ、データへの当てはまりを図示します。

```python
import numpy as np
import matplotlib.pyplot as plt

# 仮想的なデータを用意（y = 2x + 1 にノイズを加えたデータ）
X = np.linspace(0, 10, 20)            # 0から10までの20点
true_y = 2 * X + 1                    # 真の関係: 傾き2、切片1
y = true_y + np.random.normal(scale=2, size=X.shape)  # ノイズを加える

# 最小二乗法で線形回帰パラメータを推定（polyfitを使用）
coef = np.polyfit(X, y, 1)   # 1次式でフィッティング
predicted = np.polyval(coef, X)
print("学習されたモデル: y = {:.3f} * x + {:.3f}".format(coef[0], coef[1]))

# データとモデルをプロット
plt.scatter(X, y, label="データ点")
plt.plot(X, predicted, color="red", label="フィットした直線")
plt.legend()
plt.xlabel("x")
plt.ylabel("y")
plt.title("線形回帰によるフィッティング")
plt.show()
```

上記コードでは、まず $y = 2x+1$ に従う真のモデルからノイズ付きデータを生成しています。次にNumPyの`polyfit`関数で一次式によるフィッティングを行い、係数（傾きと切片）を推定しています。最後に散布図と回帰直線を描画しています。実行すると、例えば以下のように出力されます。

```
学習されたモデル: y = 2.051 * x + 0.418
```

（プロット図）  

*図3: ノイズのあるデータ点（青）に対し、線形回帰でフィットした直線（赤）を描画した例。真のモデルが $y=2x+1$ であるのに対し、学習されたモデルはおおむねそれに近い直線となっている。*

この結果では、生成時の真の傾き2に対し学習された傾きは約2.051、切片は約0.418となっています。データに対する当てはまりを図3に示します。多少のズレはありますが、おおむねデータの傾向を捉えた直線が学習できていることが分かります。データ点が増えればモデルはさらに真の関係に近づくでしょう。

このように、機械学習ではデータをもとにモデルのパラメータを調整し、未知のデータに対しても適切な予測ができるようにします。線形回帰は非常にシンプルなモデルですが、機械学習の基本的な流れ（モデル設定→損失定義→最適化→評価）を体験することができます。

### まとめ

第3章では、機械学習の基本概念とプロセスについて学びました。機械学習とはデータから規則性を学習して予測モデルを作ることであり、入力と出力の対応関係を自動獲得する点で従来の明示的プログラミングとは異なります ([〖机器学习〗一些基本概念及符号系统 - 昕-2008 - 博客园](https://www.cnblogs.com/Belter/p/6323390.html#:~:text=%E5%A6%82%E6%9E%9C%E5%B0%86%E4%B8%80%E4%B8%AA%E7%A8%8B%E5%BA%8F%E5%A4%A7%E8%87%B4%E5%88%86%E4%B8%BA%E4%B8%89%E4%B8%AA%E9%83%A8%E5%88%86%EF%BC%9A%E8%BE%93%E5%85%A5%E3%80%81%E8%BE%93%E5%87%BA%E5%92%8C%E7%AE%97%E6%B3%95%EF%BC%8C%E9%82%A3%E4%B9%88%E4%BC%A0%E7%BB%9F%E7%BC%96%E7%A8%8B%E4%B8%AD%E5%B7%B2%E7%9F%A5%E7%9A%84%E6%98%AF%E8%BE%93%E5%85%A5%E5%92%8C%E7%AE%97%E6%B3%95%EF%BC%8C%E9%9C%80%E8%A6%81%E6%B1%82%E8%BE%93%E5%87%BA%EF%BC%9B%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%88%99%E6%98%AF%E5%B7%B2%E7%9F%A5%E8%BE%93%E5%85%A5%E5%92%8C%E8%BE%93%E5%87%BA%EF%BC%8C%E9%9C%80%E8%A6%81%E9%80%9A%E8%BF%87%E8%AE%AD%E7%BB%83%EF%BC%88%E5%AD%A6%E4%B9%A0%EF%BC%89%E6%9D%A5%E5%BE%97%E5%88%B0%E6%9C%89%E6%B3%9B%E5%8C%96%E8%83%BD%20%E5%8A%9B%E7%9A%84%E7%AE%97%E6%B3%95%E3%80%82))。教師あり学習・教師なし学習・強化学習といった分類、モデルの汎化性能や過学習の問題、損失関数を用いたパラメータ最適化の考え方など、機械学習に共通する重要事項を押さえました。特に教師あり学習の一連の流れ（データ分割、モデル訓練、評価）は機械学習の応用で常に出てくるパターンです。

ここまでの基礎（コンピュータサイエンスの基盤、数学、機械学習概論）を踏まえれば、いよいよ深層学習やTransformerの詳細に進む準備が整いました。第4章以降では、ニューラルネットワークの原理や最先端のTransformerモデルについてゼロから学んでいきましょう。

**参考文献・情報源:** 本資料の作成にあたっては、機械学習のオンライン講義資料【4】や技術解説記事【22】【24】、文部科学省関連資料【20】などを参照し、内容を整理・統合しました。また、一部中国語資料【56】の知見も取り入れ、よりわかりやすい説明となるよう努めました。各章中の引用番号【】で示した文献・サイトも、理解を深めるのに役立ちますのでぜひ参照してください。